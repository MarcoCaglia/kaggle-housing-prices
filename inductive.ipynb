{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Competition: House Prices: Advanced Regression Techniques\n",
    "https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data\n",
    "## Part 1: Machine Learning\n",
    "### Outline:\n",
    "1. Preparation\n",
    "2. Testing and Selecting Base Models\n",
    "3. Finetuning of the Best Model\n",
    "4. Comparison with simple DLN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparation: Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, PolynomialFeatures, Normalizer, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor,GradientBoostingRegressor\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import r2_score, make_scorer\n",
    "from scipy.stats import skew, kurtosis\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "from kaggle_scorer import rmsle, rmsle_validation\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation,Flatten\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>...</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice_log</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>CollgCr</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>12.247694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Veenker</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>12.109011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>CollgCr</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>12.317167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Crawfor</td>\n",
       "      <td>...</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>11.849398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NoRidge</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>12.429216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    MSSubClass MSZoning  LotArea Street LotShape LandContour Utilities  \\\n",
       "Id                                                                       \n",
       "1           60       RL     8450   Pave      Reg         Lvl    AllPub   \n",
       "2           20       RL     9600   Pave      Reg         Lvl    AllPub   \n",
       "3           60       RL    11250   Pave      IR1         Lvl    AllPub   \n",
       "4           70       RL     9550   Pave      IR1         Lvl    AllPub   \n",
       "5           60       RL    14260   Pave      IR1         Lvl    AllPub   \n",
       "\n",
       "   LotConfig LandSlope Neighborhood  ... EnclosedPorch 3SsnPorch ScreenPorch  \\\n",
       "Id                                   ...                                       \n",
       "1     Inside       Gtl      CollgCr  ...             0         0           0   \n",
       "2        FR2       Gtl      Veenker  ...             0         0           0   \n",
       "3     Inside       Gtl      CollgCr  ...             0         0           0   \n",
       "4     Corner       Gtl      Crawfor  ...           272         0           0   \n",
       "5        FR2       Gtl      NoRidge  ...             0         0           0   \n",
       "\n",
       "   PoolArea  MiscVal  MoSold  YrSold  SaleType SaleCondition SalePrice_log  \n",
       "Id                                                                          \n",
       "1         0        0       2    2008        WD        Normal     12.247694  \n",
       "2         0        0       5    2007        WD        Normal     12.109011  \n",
       "3         0        0       9    2008        WD        Normal     12.317167  \n",
       "4         0        0       2    2006        WD       Abnorml     11.849398  \n",
       "5         0        0      12    2008        WD        Normal     12.429216  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preparation: Import processed dataset\n",
    "path = 'train_processed.csv'\n",
    "df = pd.read_csv(path, index_col='Id')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marco\\Anaconda3\\envs\\kaggle_housing_comp\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Preparation: Split the dataset in train and test data\n",
    "X = np.array(df.drop('SalePrice_log',axis=1))\n",
    "y = np.array(df.loc[:,'SalePrice_log'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,train_size=0.80,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparation: Prepare Pipelines\n",
    "poly_fit = PolynomialFeatures(degree=2)\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "norm = Normalizer()\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "rand_for = RandomForestRegressor()\n",
    "ada_boost = AdaBoostRegressor()\n",
    "grad_boost = GradientBoostingRegressor()\n",
    "\n",
    "lin_pipe = Pipeline([('OneHotEncoder',encoder),\n",
    "                     ('Normalizer',norm),\n",
    "                     ('StandardScaler',scaler),\n",
    "                     ('LinearRegression',lin_reg)])\n",
    "\n",
    "rand_for_pipe = Pipeline([('OneHotEncoder',encoder),\n",
    "                          ('Normalizer',norm),\n",
    "                          ('StandardScaler',scaler),\n",
    "                          ('RandomForest',rand_for)])\n",
    "\n",
    "ada_boost_pipe = Pipeline([('OneHotEncoder',encoder),\n",
    "                           ('Normalizer',norm),\n",
    "                           ('StandardScaler',scaler),\n",
    "                           ('AdaBoost',ada_boost)])\n",
    "\n",
    "grad_boost_pipe = Pipeline([('OneHotEncoder',encoder),\n",
    "                            ('Normalizer',norm),\n",
    "                            ('StandardScaler',scaler),\n",
    "                            ('GradientBoosting',grad_boost)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing and Selecting Base Models: Defining test function\n",
    "def test_model(pipeline,X_train=X_train,X_test=X_test,y_train=y_train,y_test=y_test):\n",
    "    \n",
    "    start_time = dt.datetime.now()\n",
    "    pipeline.fit(X_train,y_train)\n",
    "    end_time = dt.datetime.now()\n",
    "    fit_time = dt.timedelta.total_seconds(end_time-start_time)\n",
    "    \n",
    "    yhat_train = pipeline.predict(X_train)\n",
    "    train_score = rmsle(y_train,yhat_train)\n",
    "    \n",
    "    yhat = pipeline.predict(X_test)\n",
    "    test_score = rmsle(y_test,yhat)\n",
    "    \n",
    "    return np.array((fit_time,train_score,test_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marco\\Anaconda3\\envs\\kaggle_housing_comp\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Testing and Selecting Base Models: Testing\n",
    "pipe_list = [lin_pipe,rand_for_pipe,ada_boost_pipe,grad_boost_pipe]\n",
    "results = np.empty((4,3))\n",
    "\n",
    "test_map = map(test_model,pipe_list)\n",
    "i = 0\n",
    "for result in test_map:\n",
    "    results[i]=result\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Testing and Selecting Base Models: Visualize Test Results\n",
    "fig,ax = plt.subplots(figsize=(10,5))\n",
    "names = ['Linear','RFR','ABR','GBR']\n",
    "titles = ['Training Time','Training Accuracy','Test Accuracy']\n",
    "y_titles = ['Seconds','RMSLE','RMSLE']\n",
    "plot_info = zip(titles,y_titles)\n",
    "\n",
    "for i,titles in enumerate(plot_info):\n",
    "    plt.subplot(1,3,i+1)\n",
    "    plt.bar(x=names,height=results[:,i])\n",
    "    plt.title(titles[0])\n",
    "    plt.ylabel(titles[1])\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is apparent, that the linear model tales the least training time, thanks to its simplicity. It's  And although it is performing well on the training and the test set, it is the least fitting one. Luckily, the second fastest model (GBR) is also the best model in terms of test accuracy, which is why, we will go with that model for now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finetuning of the best model: Define hyperparameters to be tuned\n",
    "param_grid = {'GradientBoosting__learning_rate':[0.001,0.005,0.01,0.1],\n",
    "              'GradientBoosting__n_estimators':[50,100,200],\n",
    "              'GradientBoosting__max_depth':[1,3,5]}\n",
    "\n",
    "grad_boost_pipe_cv = GridSearchCV(grad_boost_pipe,param_grid=param_grid,cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finetuning of the best model: Fit final model\n",
    "grad_boost_pipe_cv.fit(X_train,y_train)\n",
    "\n",
    "final_results = test_model(grad_boost_pipe_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finetuning of the best model: Display final results\n",
    "print('Total Runtime: {}'.format(final_results[0]))\n",
    "print('Training Score (RMSLE): {}'.format(final_results[1]))\n",
    "print('Test Score (RMSLE) {}'.format(final_results[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model versus Deep Learning Network: Special pipeline\n",
    "dln_pipe = Pipeline([('OneHotEncoder',encoder),\n",
    "                     ('Normalizer',norm),\n",
    "                     ('StandardScaler',scaler),\n",
    "                     ('TruncatedSVD',TruncatedSVD(n_components=7))])\n",
    "\n",
    "input_train = dln_pipe.fit_transform(X_train)\n",
    "labels_train = y_train.reshape(-1,1)\n",
    "input_test = dln_pipe.fit_transform(X_test)\n",
    "labels_test = y_test.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_31 (Dense)             (None, 128)               1024      \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 165,889\n",
      "Trainable params: 165,889\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128,kernel_initializer='normal',input_dim=input_train.shape[1],activation='relu'))\n",
    "model.add(Dense(256,kernel_initializer='normal',activation='relu'))\n",
    "model.add(Dense(256,kernel_initializer='normal',activation='relu'))\n",
    "model.add(Dense(256,kernel_initializer='normal',activation='relu'))\n",
    "model.add(Dense(1,kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "model.compile(loss = 'mean_absolute_error',optimizer='adam',metrics=['mean_absolute_error'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 928 samples, validate on 233 samples\n",
      "Epoch 1/500\n",
      "928/928 [==============================] - 2s 2ms/step - loss: 594755990068.9655 - mean_absolute_error: 594755990068.9655 - val_loss: 22063909347.4335 - val_mean_absolute_error: 22063909347.4335\n",
      "Epoch 2/500\n",
      "928/928 [==============================] - 0s 130us/step - loss: 181956871309.2414 - mean_absolute_error: 181956871309.2414 - val_loss: 161324203399.1416 - val_mean_absolute_error: 161324203399.1416\n",
      "Epoch 3/500\n",
      "928/928 [==============================] - 0s 119us/step - loss: 67978487772.6897 - mean_absolute_error: 67978487772.6897 - val_loss: 18173063721.7511 - val_mean_absolute_error: 18173063721.7511\n",
      "Epoch 4/500\n",
      "928/928 [==============================] - 0s 159us/step - loss: 22726455436.7586 - mean_absolute_error: 22726455436.7586 - val_loss: 28844216161.7854 - val_mean_absolute_error: 28844216161.7854\n",
      "Epoch 5/500\n",
      "928/928 [==============================] - 0s 132us/step - loss: 22468015762.2069 - mean_absolute_error: 22468015762.2069 - val_loss: 17948934302.2146 - val_mean_absolute_error: 17948934302.2146\n",
      "Epoch 6/500\n",
      "928/928 [==============================] - 0s 163us/step - loss: 15573289984.0000 - mean_absolute_error: 15573289984.0000 - val_loss: 36788722920.9270 - val_mean_absolute_error: 36788722920.9270\n",
      "Epoch 7/500\n",
      "928/928 [==============================] - 0s 142us/step - loss: 17333067784.8276 - mean_absolute_error: 17333067784.8276 - val_loss: 677738310.5923 - val_mean_absolute_error: 677738310.5923\n",
      "Epoch 8/500\n",
      "928/928 [==============================] - 0s 158us/step - loss: 28853606576.5517 - mean_absolute_error: 28853606576.5517 - val_loss: 1333221154.6094 - val_mean_absolute_error: 1333221154.6094\n",
      "Epoch 9/500\n",
      "928/928 [==============================] - 0s 215us/step - loss: 22173270889.9310 - mean_absolute_error: 22173270889.9310 - val_loss: 13518743314.6781 - val_mean_absolute_error: 13518743314.6781\n",
      "Epoch 10/500\n",
      "928/928 [==============================] - 0s 211us/step - loss: 13027477270.0690 - mean_absolute_error: 13027477270.0690 - val_loss: 27276108092.4292 - val_mean_absolute_error: 27276108092.4292\n",
      "Epoch 11/500\n",
      "928/928 [==============================] - 0s 160us/step - loss: 16756654448.0690 - mean_absolute_error: 16756654448.0690 - val_loss: 10151968926.2146 - val_mean_absolute_error: 10151968926.2146\n",
      "Epoch 12/500\n",
      "928/928 [==============================] - 0s 220us/step - loss: 7261610884.6897 - mean_absolute_error: 7261610884.6897 - val_loss: 990247958.7983 - val_mean_absolute_error: 990247958.7983\n",
      "Epoch 13/500\n",
      "928/928 [==============================] - 0s 235us/step - loss: 9042586315.0345 - mean_absolute_error: 9042586315.0345 - val_loss: 16020641910.6609 - val_mean_absolute_error: 16020641910.6609\n",
      "Epoch 14/500\n",
      "928/928 [==============================] - 0s 132us/step - loss: 8261969497.5862 - mean_absolute_error: 8261969497.5862 - val_loss: 19211353953.7854 - val_mean_absolute_error: 19211353953.7854\n",
      "Epoch 15/500\n",
      "928/928 [==============================] - 0s 196us/step - loss: 6368594593.1034 - mean_absolute_error: 6368594593.1034 - val_loss: 672615212.4979 - val_mean_absolute_error: 672615212.4979\n",
      "Epoch 16/500\n",
      "928/928 [==============================] - 0s 245us/step - loss: 1001724579.5850 - mean_absolute_error: 1001724579.5850 - val_loss: 12.0162 - val_mean_absolute_error: 12.0162\n",
      "Epoch 17/500\n",
      "928/928 [==============================] - 0s 160us/step - loss: 11.8870 - mean_absolute_error: 11.8870 - val_loss: 11.7151 - val_mean_absolute_error: 11.7151\n",
      "Epoch 18/500\n",
      "928/928 [==============================] - 0s 156us/step - loss: 11.2797 - mean_absolute_error: 11.2797 - val_loss: 10.7017 - val_mean_absolute_error: 10.7017\n",
      "Epoch 19/500\n",
      "928/928 [==============================] - 0s 156us/step - loss: 9.7920 - mean_absolute_error: 9.7920 - val_loss: 8.6771 - val_mean_absolute_error: 8.6771\n",
      "Epoch 20/500\n",
      "928/928 [==============================] - 0s 141us/step - loss: 7.2328 - mean_absolute_error: 7.2328 - val_loss: 5.5352 - val_mean_absolute_error: 5.5352\n",
      "Epoch 21/500\n",
      "928/928 [==============================] - 0s 133us/step - loss: 3.5356 - mean_absolute_error: 3.5356 - val_loss: 1.2394 - val_mean_absolute_error: 1.2394\n",
      "Epoch 22/500\n",
      "928/928 [==============================] - 0s 145us/step - loss: 0.4996 - mean_absolute_error: 0.4996 - val_loss: 0.3624 - val_mean_absolute_error: 0.3624\n",
      "Epoch 23/500\n",
      "928/928 [==============================] - 0s 147us/step - loss: 0.3289 - mean_absolute_error: 0.3289 - val_loss: 0.3034 - val_mean_absolute_error: 0.3034\n",
      "Epoch 24/500\n",
      "928/928 [==============================] - 0s 160us/step - loss: 0.3105 - mean_absolute_error: 0.3105 - val_loss: 0.3018 - val_mean_absolute_error: 0.3018\n",
      "Epoch 25/500\n",
      "928/928 [==============================] - 0s 238us/step - loss: 0.3101 - mean_absolute_error: 0.3101 - val_loss: 0.3019 - val_mean_absolute_error: 0.3019\n",
      "Epoch 26/500\n",
      "928/928 [==============================] - 0s 241us/step - loss: 0.3112 - mean_absolute_error: 0.3112 - val_loss: 0.3033 - val_mean_absolute_error: 0.3033\n",
      "Epoch 27/500\n",
      "928/928 [==============================] - 0s 204us/step - loss: 0.3110 - mean_absolute_error: 0.3110 - val_loss: 0.3020 - val_mean_absolute_error: 0.3020\n",
      "Epoch 28/500\n",
      "928/928 [==============================] - 0s 260us/step - loss: 0.3125 - mean_absolute_error: 0.3125 - val_loss: 0.3018 - val_mean_absolute_error: 0.3018\n",
      "Epoch 29/500\n",
      "928/928 [==============================] - 0s 205us/step - loss: 0.3107 - mean_absolute_error: 0.3107 - val_loss: 0.3022 - val_mean_absolute_error: 0.3022\n",
      "Epoch 30/500\n",
      "928/928 [==============================] - 0s 141us/step - loss: 0.3103 - mean_absolute_error: 0.3103 - val_loss: 0.3079 - val_mean_absolute_error: 0.3079\n",
      "Epoch 31/500\n",
      "928/928 [==============================] - 0s 169us/step - loss: 0.3114 - mean_absolute_error: 0.3114 - val_loss: 0.3020 - val_mean_absolute_error: 0.3020\n",
      "Epoch 32/500\n",
      "928/928 [==============================] - 0s 145us/step - loss: 0.3121 - mean_absolute_error: 0.3121 - val_loss: 0.3029 - val_mean_absolute_error: 0.3029\n",
      "Epoch 33/500\n",
      "928/928 [==============================] - 0s 152us/step - loss: 0.3107 - mean_absolute_error: 0.3107 - val_loss: 0.3066 - val_mean_absolute_error: 0.3066\n",
      "Epoch 34/500\n",
      "928/928 [==============================] - 0s 152us/step - loss: 0.3113 - mean_absolute_error: 0.3113 - val_loss: 0.3038 - val_mean_absolute_error: 0.3038\n",
      "Epoch 35/500\n",
      "928/928 [==============================] - 0s 147us/step - loss: 0.3111 - mean_absolute_error: 0.3111 - val_loss: 0.3083 - val_mean_absolute_error: 0.3083\n",
      "Epoch 36/500\n",
      "928/928 [==============================] - 0s 298us/step - loss: 0.3108 - mean_absolute_error: 0.3108 - val_loss: 0.3025 - val_mean_absolute_error: 0.3025\n",
      "Epoch 37/500\n",
      "928/928 [==============================] - 0s 193us/step - loss: 0.3131 - mean_absolute_error: 0.3131 - val_loss: 0.3058 - val_mean_absolute_error: 0.3058\n",
      "Epoch 38/500\n",
      "928/928 [==============================] - 0s 221us/step - loss: 0.3095 - mean_absolute_error: 0.3095 - val_loss: 0.3025 - val_mean_absolute_error: 0.3025\n",
      "Epoch 39/500\n",
      "928/928 [==============================] - 0s 229us/step - loss: 0.3105 - mean_absolute_error: 0.3105 - val_loss: 0.3095 - val_mean_absolute_error: 0.3095\n",
      "Epoch 40/500\n",
      "928/928 [==============================] - 0s 229us/step - loss: 0.3144 - mean_absolute_error: 0.3144 - val_loss: 0.3051 - val_mean_absolute_error: 0.3051\n",
      "Epoch 41/500\n",
      "928/928 [==============================] - 0s 236us/step - loss: 0.3127 - mean_absolute_error: 0.3127 - val_loss: 0.3062 - val_mean_absolute_error: 0.3062\n",
      "Epoch 42/500\n",
      "928/928 [==============================] - 0s 175us/step - loss: 0.3139 - mean_absolute_error: 0.3139 - val_loss: 0.3018 - val_mean_absolute_error: 0.3018\n",
      "Epoch 43/500\n",
      "928/928 [==============================] - 0s 168us/step - loss: 0.3112 - mean_absolute_error: 0.3112 - val_loss: 0.3022 - val_mean_absolute_error: 0.3022\n",
      "Epoch 44/500\n",
      "928/928 [==============================] - 0s 206us/step - loss: 0.3110 - mean_absolute_error: 0.3110 - val_loss: 0.3037 - val_mean_absolute_error: 0.3037\n",
      "Epoch 45/500\n",
      "928/928 [==============================] - 0s 169us/step - loss: 0.3103 - mean_absolute_error: 0.3103 - val_loss: 0.3034 - val_mean_absolute_error: 0.3034\n",
      "Epoch 46/500\n",
      "928/928 [==============================] - 0s 178us/step - loss: 0.3133 - mean_absolute_error: 0.3133 - val_loss: 0.3030 - val_mean_absolute_error: 0.3030\n",
      "Epoch 47/500\n",
      "928/928 [==============================] - 0s 161us/step - loss: 0.3110 - mean_absolute_error: 0.3110 - val_loss: 0.3019 - val_mean_absolute_error: 0.3019\n",
      "Epoch 48/500\n",
      "928/928 [==============================] - 0s 159us/step - loss: 0.3111 - mean_absolute_error: 0.3111 - val_loss: 0.3132 - val_mean_absolute_error: 0.3132\n",
      "Epoch 49/500\n",
      "928/928 [==============================] - 0s 260us/step - loss: 0.3177 - mean_absolute_error: 0.3177 - val_loss: 0.3182 - val_mean_absolute_error: 0.3182\n",
      "Epoch 50/500\n",
      "928/928 [==============================] - 0s 193us/step - loss: 0.3145 - mean_absolute_error: 0.3145 - val_loss: 0.3059 - val_mean_absolute_error: 0.3059\n",
      "Epoch 51/500\n",
      "928/928 [==============================] - 0s 161us/step - loss: 0.3114 - mean_absolute_error: 0.3114 - val_loss: 0.3019 - val_mean_absolute_error: 0.3019\n",
      "Epoch 52/500\n",
      "928/928 [==============================] - 0s 284us/step - loss: 0.3104 - mean_absolute_error: 0.3104 - val_loss: 0.3054 - val_mean_absolute_error: 0.3054\n",
      "Epoch 53/500\n",
      "928/928 [==============================] - 0s 185us/step - loss: 0.3132 - mean_absolute_error: 0.3132 - val_loss: 0.3057 - val_mean_absolute_error: 0.3057\n",
      "Epoch 54/500\n",
      "928/928 [==============================] - 0s 157us/step - loss: 0.3108 - mean_absolute_error: 0.3108 - val_loss: 0.3021 - val_mean_absolute_error: 0.3021\n",
      "Epoch 55/500\n",
      "928/928 [==============================] - 0s 176us/step - loss: 0.3093 - mean_absolute_error: 0.3093 - val_loss: 0.3109 - val_mean_absolute_error: 0.3109\n",
      "Epoch 56/500\n",
      "928/928 [==============================] - 0s 181us/step - loss: 0.3111 - mean_absolute_error: 0.3111 - val_loss: 0.3052 - val_mean_absolute_error: 0.3052\n",
      "Epoch 57/500\n",
      "928/928 [==============================] - 0s 221us/step - loss: 0.3122 - mean_absolute_error: 0.3122 - val_loss: 0.3019 - val_mean_absolute_error: 0.3019\n",
      "Epoch 58/500\n",
      "928/928 [==============================] - 0s 175us/step - loss: 0.3116 - mean_absolute_error: 0.3116 - val_loss: 0.3040 - val_mean_absolute_error: 0.3040\n",
      "Epoch 59/500\n",
      "928/928 [==============================] - 0s 148us/step - loss: 0.3150 - mean_absolute_error: 0.3150 - val_loss: 0.3055 - val_mean_absolute_error: 0.3055\n",
      "Epoch 60/500\n",
      "928/928 [==============================] - 0s 152us/step - loss: 0.3107 - mean_absolute_error: 0.3107 - val_loss: 0.3018 - val_mean_absolute_error: 0.3018\n",
      "Epoch 61/500\n",
      "928/928 [==============================] - 0s 149us/step - loss: 0.3106 - mean_absolute_error: 0.3106 - val_loss: 0.3020 - val_mean_absolute_error: 0.3020\n",
      "Epoch 62/500\n",
      "928/928 [==============================] - 0s 157us/step - loss: 0.3109 - mean_absolute_error: 0.3109 - val_loss: 0.3019 - val_mean_absolute_error: 0.3019\n",
      "Epoch 63/500\n",
      "928/928 [==============================] - 0s 174us/step - loss: 0.3110 - mean_absolute_error: 0.3110 - val_loss: 0.3051 - val_mean_absolute_error: 0.3051\n",
      "Epoch 64/500\n",
      "928/928 [==============================] - 0s 244us/step - loss: 0.3106 - mean_absolute_error: 0.3106 - val_loss: 0.3036 - val_mean_absolute_error: 0.3036\n",
      "Epoch 65/500\n",
      "928/928 [==============================] - 0s 189us/step - loss: 0.3103 - mean_absolute_error: 0.3103 - val_loss: 0.3018 - val_mean_absolute_error: 0.3018\n",
      "Epoch 66/500\n",
      "928/928 [==============================] - 0s 160us/step - loss: 0.3119 - mean_absolute_error: 0.3119 - val_loss: 0.3018 - val_mean_absolute_error: 0.3018\n",
      "Epoch 67/500\n",
      "928/928 [==============================] - 0s 153us/step - loss: 0.3116 - mean_absolute_error: 0.3116 - val_loss: 0.3020 - val_mean_absolute_error: 0.3020\n",
      "Epoch 68/500\n",
      "928/928 [==============================] - 0s 206us/step - loss: 0.3099 - mean_absolute_error: 0.3099 - val_loss: 0.3020 - val_mean_absolute_error: 0.3020\n",
      "Epoch 69/500\n",
      "928/928 [==============================] - 0s 257us/step - loss: 0.3104 - mean_absolute_error: 0.3104 - val_loss: 0.3027 - val_mean_absolute_error: 0.3027\n",
      "Epoch 70/500\n",
      "928/928 [==============================] - 0s 212us/step - loss: 0.3102 - mean_absolute_error: 0.3102 - val_loss: 0.3018 - val_mean_absolute_error: 0.3018\n",
      "Epoch 71/500\n",
      "928/928 [==============================] - 0s 181us/step - loss: 0.3133 - mean_absolute_error: 0.3133 - val_loss: 0.3021 - val_mean_absolute_error: 0.3021\n",
      "Epoch 72/500\n",
      "928/928 [==============================] - 0s 192us/step - loss: 0.3112 - mean_absolute_error: 0.3112 - val_loss: 0.3028 - val_mean_absolute_error: 0.3028\n",
      "Epoch 73/500\n",
      "928/928 [==============================] - 0s 178us/step - loss: 0.3113 - mean_absolute_error: 0.3113 - val_loss: 0.3034 - val_mean_absolute_error: 0.3034\n",
      "Epoch 74/500\n",
      "928/928 [==============================] - 0s 167us/step - loss: 0.3118 - mean_absolute_error: 0.3118 - val_loss: 0.3019 - val_mean_absolute_error: 0.3019\n",
      "Epoch 75/500\n",
      "928/928 [==============================] - 0s 155us/step - loss: 0.3118 - mean_absolute_error: 0.3118 - val_loss: 0.3033 - val_mean_absolute_error: 0.3033\n",
      "Epoch 76/500\n",
      "928/928 [==============================] - 0s 248us/step - loss: 0.3104 - mean_absolute_error: 0.3104 - val_loss: 0.3021 - val_mean_absolute_error: 0.3021\n",
      "Epoch 77/500\n",
      "928/928 [==============================] - 0s 166us/step - loss: 0.3104 - mean_absolute_error: 0.3104 - val_loss: 0.3038 - val_mean_absolute_error: 0.3038\n",
      "Epoch 78/500\n",
      "928/928 [==============================] - 0s 153us/step - loss: 0.3124 - mean_absolute_error: 0.3124 - val_loss: 0.3084 - val_mean_absolute_error: 0.3084\n",
      "Epoch 79/500\n",
      "928/928 [==============================] - 0s 154us/step - loss: 0.3124 - mean_absolute_error: 0.3124 - val_loss: 0.3030 - val_mean_absolute_error: 0.3030\n",
      "Epoch 80/500\n",
      "928/928 [==============================] - 0s 214us/step - loss: 0.3107 - mean_absolute_error: 0.3107 - val_loss: 0.3097 - val_mean_absolute_error: 0.3097\n",
      "Epoch 81/500\n",
      "928/928 [==============================] - 0s 187us/step - loss: 0.3103 - mean_absolute_error: 0.3103 - val_loss: 0.3050 - val_mean_absolute_error: 0.3050\n",
      "Epoch 82/500\n",
      "928/928 [==============================] - 0s 185us/step - loss: 0.3105 - mean_absolute_error: 0.3105 - val_loss: 0.3022 - val_mean_absolute_error: 0.3022\n",
      "Epoch 83/500\n",
      "928/928 [==============================] - 0s 211us/step - loss: 0.3111 - mean_absolute_error: 0.3111 - val_loss: 0.3090 - val_mean_absolute_error: 0.3090\n",
      "Epoch 84/500\n",
      "928/928 [==============================] - 0s 231us/step - loss: 0.3107 - mean_absolute_error: 0.3107 - val_loss: 0.3111 - val_mean_absolute_error: 0.3111\n",
      "Epoch 85/500\n",
      "928/928 [==============================] - 0s 172us/step - loss: 0.3130 - mean_absolute_error: 0.3130 - val_loss: 0.3021 - val_mean_absolute_error: 0.3021\n",
      "Epoch 86/500\n",
      "928/928 [==============================] - 0s 159us/step - loss: 0.3106 - mean_absolute_error: 0.3106 - val_loss: 0.3036 - val_mean_absolute_error: 0.3036\n",
      "Epoch 87/500\n",
      "928/928 [==============================] - 0s 154us/step - loss: 0.3109 - mean_absolute_error: 0.3109 - val_loss: 0.3026 - val_mean_absolute_error: 0.3026\n",
      "Epoch 88/500\n",
      "928/928 [==============================] - 0s 139us/step - loss: 0.3099 - mean_absolute_error: 0.3099 - val_loss: 0.3036 - val_mean_absolute_error: 0.3036\n",
      "Epoch 89/500\n",
      "928/928 [==============================] - 0s 142us/step - loss: 0.3122 - mean_absolute_error: 0.3122 - val_loss: 0.3024 - val_mean_absolute_error: 0.3024\n",
      "Epoch 90/500\n",
      "928/928 [==============================] - 0s 141us/step - loss: 0.3127 - mean_absolute_error: 0.3127 - val_loss: 0.3019 - val_mean_absolute_error: 0.3019\n",
      "Epoch 91/500\n",
      "928/928 [==============================] - 0s 152us/step - loss: 0.3109 - mean_absolute_error: 0.3109 - val_loss: 0.3048 - val_mean_absolute_error: 0.3048\n",
      "Epoch 92/500\n",
      "928/928 [==============================] - 0s 144us/step - loss: 0.3103 - mean_absolute_error: 0.3103 - val_loss: 0.3022 - val_mean_absolute_error: 0.3022\n",
      "Epoch 93/500\n",
      "928/928 [==============================] - 0s 159us/step - loss: 0.3117 - mean_absolute_error: 0.3117 - val_loss: 0.3033 - val_mean_absolute_error: 0.3033\n",
      "Epoch 94/500\n",
      "928/928 [==============================] - 0s 133us/step - loss: 0.3106 - mean_absolute_error: 0.3106 - val_loss: 0.3041 - val_mean_absolute_error: 0.3041\n",
      "Epoch 95/500\n",
      "928/928 [==============================] - 0s 147us/step - loss: 0.3108 - mean_absolute_error: 0.3108 - val_loss: 0.3054 - val_mean_absolute_error: 0.3054\n",
      "Epoch 96/500\n",
      "928/928 [==============================] - 0s 150us/step - loss: 0.3103 - mean_absolute_error: 0.3103 - val_loss: 0.3025 - val_mean_absolute_error: 0.3025\n",
      "Epoch 97/500\n",
      "928/928 [==============================] - 0s 214us/step - loss: 0.3129 - mean_absolute_error: 0.3129 - val_loss: 0.3024 - val_mean_absolute_error: 0.3024\n",
      "Epoch 98/500\n",
      "928/928 [==============================] - 0s 173us/step - loss: 0.3118 - mean_absolute_error: 0.3118 - val_loss: 0.3018 - val_mean_absolute_error: 0.3018\n",
      "Epoch 99/500\n",
      "928/928 [==============================] - 0s 172us/step - loss: 0.3103 - mean_absolute_error: 0.3103 - val_loss: 0.3020 - val_mean_absolute_error: 0.3020\n",
      "Epoch 100/500\n",
      "928/928 [==============================] - 0s 153us/step - loss: 0.3109 - mean_absolute_error: 0.3109 - val_loss: 0.3027 - val_mean_absolute_error: 0.3027\n",
      "Epoch 101/500\n",
      "928/928 [==============================] - 0s 223us/step - loss: 0.3146 - mean_absolute_error: 0.3146 - val_loss: 0.3018 - val_mean_absolute_error: 0.3018\n",
      "Epoch 102/500\n",
      "928/928 [==============================] - 0s 212us/step - loss: 0.3123 - mean_absolute_error: 0.3123 - val_loss: 0.3018 - val_mean_absolute_error: 0.3018\n",
      "Epoch 103/500\n",
      "928/928 [==============================] - 0s 160us/step - loss: 0.3106 - mean_absolute_error: 0.3106 - val_loss: 0.3021 - val_mean_absolute_error: 0.3021\n",
      "Epoch 104/500\n",
      "928/928 [==============================] - 0s 152us/step - loss: 0.3154 - mean_absolute_error: 0.3154 - val_loss: 0.3029 - val_mean_absolute_error: 0.3029\n",
      "Epoch 105/500\n",
      "928/928 [==============================] - 0s 156us/step - loss: 0.3108 - mean_absolute_error: 0.3108 - val_loss: 0.3055 - val_mean_absolute_error: 0.3055\n",
      "Epoch 106/500\n",
      "928/928 [==============================] - 0s 163us/step - loss: 0.3144 - mean_absolute_error: 0.3144 - val_loss: 0.3091 - val_mean_absolute_error: 0.3091\n",
      "Epoch 107/500\n",
      "928/928 [==============================] - 0s 234us/step - loss: 0.3140 - mean_absolute_error: 0.3140 - val_loss: 0.3068 - val_mean_absolute_error: 0.3068\n",
      "Epoch 108/500\n",
      "928/928 [==============================] - 0s 179us/step - loss: 0.3109 - mean_absolute_error: 0.3109 - val_loss: 0.3044 - val_mean_absolute_error: 0.3044\n",
      "Epoch 109/500\n",
      "928/928 [==============================] - 0s 142us/step - loss: 0.3118 - mean_absolute_error: 0.3118 - val_loss: 0.3019 - val_mean_absolute_error: 0.3019\n",
      "Epoch 110/500\n",
      "928/928 [==============================] - 0s 188us/step - loss: 0.3108 - mean_absolute_error: 0.3108 - val_loss: 0.3065 - val_mean_absolute_error: 0.3065\n",
      "Epoch 111/500\n",
      "928/928 [==============================] - 0s 234us/step - loss: 0.3122 - mean_absolute_error: 0.3122 - val_loss: 0.3019 - val_mean_absolute_error: 0.3019\n",
      "Epoch 112/500\n",
      "928/928 [==============================] - 0s 183us/step - loss: 0.3104 - mean_absolute_error: 0.3104 - val_loss: 0.3024 - val_mean_absolute_error: 0.3024\n",
      "Epoch 113/500\n",
      "928/928 [==============================] - 0s 164us/step - loss: 0.3105 - mean_absolute_error: 0.3105 - val_loss: 0.3061 - val_mean_absolute_error: 0.3061\n",
      "Epoch 114/500\n",
      "928/928 [==============================] - 0s 166us/step - loss: 0.3102 - mean_absolute_error: 0.3102 - val_loss: 0.3035 - val_mean_absolute_error: 0.3035\n",
      "Epoch 115/500\n",
      "928/928 [==============================] - 0s 143us/step - loss: 0.3102 - mean_absolute_error: 0.3102 - val_loss: 0.3026 - val_mean_absolute_error: 0.3026\n",
      "Epoch 116/500\n",
      "928/928 [==============================] - 0s 234us/step - loss: 0.3114 - mean_absolute_error: 0.3114 - val_loss: 0.3020 - val_mean_absolute_error: 0.3020\n",
      "Epoch 117/500\n",
      "928/928 [==============================] - 0s 242us/step - loss: 0.3112 - mean_absolute_error: 0.3112 - val_loss: 0.3063 - val_mean_absolute_error: 0.3063\n",
      "Epoch 118/500\n",
      "928/928 [==============================] - 0s 158us/step - loss: 0.3141 - mean_absolute_error: 0.3141 - val_loss: 0.3101 - val_mean_absolute_error: 0.3101\n",
      "Epoch 119/500\n",
      "928/928 [==============================] - 0s 182us/step - loss: 0.3119 - mean_absolute_error: 0.3119 - val_loss: 0.3031 - val_mean_absolute_error: 0.3031\n",
      "Epoch 120/500\n",
      "928/928 [==============================] - 0s 179us/step - loss: 0.3117 - mean_absolute_error: 0.3117 - val_loss: 0.3032 - val_mean_absolute_error: 0.3032\n",
      "Epoch 121/500\n",
      "928/928 [==============================] - 0s 184us/step - loss: 0.3137 - mean_absolute_error: 0.3137 - val_loss: 0.3080 - val_mean_absolute_error: 0.3080\n",
      "Epoch 122/500\n",
      "928/928 [==============================] - 0s 143us/step - loss: 0.3125 - mean_absolute_error: 0.3125 - val_loss: 0.3021 - val_mean_absolute_error: 0.3021\n",
      "Epoch 123/500\n",
      "928/928 [==============================] - 0s 172us/step - loss: 0.3118 - mean_absolute_error: 0.3118 - val_loss: 0.3225 - val_mean_absolute_error: 0.3225\n",
      "Epoch 124/500\n",
      "928/928 [==============================] - 0s 144us/step - loss: 0.3108 - mean_absolute_error: 0.3108 - val_loss: 0.3024 - val_mean_absolute_error: 0.3024\n",
      "Epoch 125/500\n",
      "928/928 [==============================] - 0s 194us/step - loss: 0.3114 - mean_absolute_error: 0.3114 - val_loss: 0.3022 - val_mean_absolute_error: 0.3022\n",
      "Epoch 126/500\n",
      "928/928 [==============================] - 0s 144us/step - loss: 0.3128 - mean_absolute_error: 0.3128 - val_loss: 0.3079 - val_mean_absolute_error: 0.3079\n",
      "Epoch 127/500\n",
      "928/928 [==============================] - 0s 131us/step - loss: 0.3151 - mean_absolute_error: 0.3151 - val_loss: 0.3081 - val_mean_absolute_error: 0.3081\n",
      "Epoch 128/500\n",
      "928/928 [==============================] - 0s 135us/step - loss: 0.3131 - mean_absolute_error: 0.3131 - val_loss: 0.3045 - val_mean_absolute_error: 0.3045\n",
      "Epoch 129/500\n",
      "928/928 [==============================] - 0s 149us/step - loss: 0.3138 - mean_absolute_error: 0.3138 - val_loss: 0.3040 - val_mean_absolute_error: 0.3040\n",
      "Epoch 130/500\n",
      "928/928 [==============================] - 0s 161us/step - loss: 0.3147 - mean_absolute_error: 0.3147 - val_loss: 0.3038 - val_mean_absolute_error: 0.3038\n",
      "Epoch 131/500\n",
      "928/928 [==============================] - 0s 153us/step - loss: 0.3119 - mean_absolute_error: 0.3119 - val_loss: 0.3024 - val_mean_absolute_error: 0.3024\n",
      "Epoch 132/500\n",
      "928/928 [==============================] - 0s 188us/step - loss: 0.3137 - mean_absolute_error: 0.3137 - val_loss: 0.3107 - val_mean_absolute_error: 0.3107\n",
      "Epoch 133/500\n",
      "928/928 [==============================] - 0s 166us/step - loss: 0.3108 - mean_absolute_error: 0.3108 - val_loss: 0.3020 - val_mean_absolute_error: 0.3020\n",
      "Epoch 134/500\n",
      "928/928 [==============================] - 0s 155us/step - loss: 0.3126 - mean_absolute_error: 0.3126 - val_loss: 0.3053 - val_mean_absolute_error: 0.3053\n",
      "Epoch 135/500\n",
      "928/928 [==============================] - 0s 153us/step - loss: 0.3127 - mean_absolute_error: 0.3127 - val_loss: 0.3041 - val_mean_absolute_error: 0.3041\n",
      "Epoch 136/500\n",
      "928/928 [==============================] - 0s 195us/step - loss: 0.3124 - mean_absolute_error: 0.3124 - val_loss: 0.3096 - val_mean_absolute_error: 0.3096\n",
      "Epoch 137/500\n",
      "928/928 [==============================] - 0s 166us/step - loss: 0.3108 - mean_absolute_error: 0.3108 - val_loss: 0.3037 - val_mean_absolute_error: 0.3037\n",
      "Epoch 138/500\n",
      "928/928 [==============================] - 0s 175us/step - loss: 0.3107 - mean_absolute_error: 0.3107 - val_loss: 0.3025 - val_mean_absolute_error: 0.3025\n",
      "Epoch 139/500\n",
      "928/928 [==============================] - 0s 148us/step - loss: 0.3123 - mean_absolute_error: 0.3123 - val_loss: 0.3059 - val_mean_absolute_error: 0.3059\n",
      "Epoch 140/500\n",
      "928/928 [==============================] - 0s 167us/step - loss: 0.3124 - mean_absolute_error: 0.3124 - val_loss: 0.3037 - val_mean_absolute_error: 0.3037\n",
      "Epoch 141/500\n",
      "928/928 [==============================] - 0s 153us/step - loss: 0.3099 - mean_absolute_error: 0.3099 - val_loss: 0.3031 - val_mean_absolute_error: 0.3031\n",
      "Epoch 142/500\n",
      "928/928 [==============================] - 0s 164us/step - loss: 0.3098 - mean_absolute_error: 0.3098 - val_loss: 0.3085 - val_mean_absolute_error: 0.3085\n",
      "Epoch 143/500\n",
      "928/928 [==============================] - 0s 149us/step - loss: 0.3103 - mean_absolute_error: 0.3103 - val_loss: 0.3021 - val_mean_absolute_error: 0.3021\n",
      "Epoch 144/500\n",
      "928/928 [==============================] - 0s 219us/step - loss: 0.3107 - mean_absolute_error: 0.3107 - val_loss: 0.3068 - val_mean_absolute_error: 0.3068\n",
      "Epoch 145/500\n",
      "928/928 [==============================] - 0s 148us/step - loss: 0.3131 - mean_absolute_error: 0.3131 - val_loss: 0.3293 - val_mean_absolute_error: 0.3293\n",
      "Epoch 146/500\n",
      "928/928 [==============================] - 0s 160us/step - loss: 0.3159 - mean_absolute_error: 0.3159 - val_loss: 0.3052 - val_mean_absolute_error: 0.3052\n",
      "Epoch 147/500\n",
      "928/928 [==============================] - 0s 147us/step - loss: 0.3135 - mean_absolute_error: 0.3135 - val_loss: 0.3054 - val_mean_absolute_error: 0.3054\n",
      "Epoch 148/500\n",
      "928/928 [==============================] - 0s 149us/step - loss: 0.3117 - mean_absolute_error: 0.3117 - val_loss: 0.3023 - val_mean_absolute_error: 0.3023\n",
      "Epoch 149/500\n",
      "928/928 [==============================] - 0s 201us/step - loss: 0.3103 - mean_absolute_error: 0.3103 - val_loss: 0.3027 - val_mean_absolute_error: 0.3027\n",
      "Epoch 150/500\n",
      "928/928 [==============================] - 0s 187us/step - loss: 0.3111 - mean_absolute_error: 0.3111 - val_loss: 0.3092 - val_mean_absolute_error: 0.3092\n",
      "Epoch 151/500\n",
      "928/928 [==============================] - 0s 150us/step - loss: 0.3109 - mean_absolute_error: 0.3109 - val_loss: 0.3018 - val_mean_absolute_error: 0.3018\n",
      "Epoch 152/500\n",
      "928/928 [==============================] - 0s 161us/step - loss: 0.3131 - mean_absolute_error: 0.3131 - val_loss: 0.3067 - val_mean_absolute_error: 0.3067\n",
      "Epoch 153/500\n",
      "928/928 [==============================] - 0s 142us/step - loss: 0.3114 - mean_absolute_error: 0.3114 - val_loss: 0.3077 - val_mean_absolute_error: 0.3077\n",
      "Epoch 154/500\n",
      "928/928 [==============================] - 0s 145us/step - loss: 0.3106 - mean_absolute_error: 0.3106 - val_loss: 0.3083 - val_mean_absolute_error: 0.3083\n",
      "Epoch 155/500\n",
      "928/928 [==============================] - 0s 149us/step - loss: 0.3101 - mean_absolute_error: 0.3101 - val_loss: 0.3021 - val_mean_absolute_error: 0.3021\n",
      "Epoch 156/500\n",
      "928/928 [==============================] - 0s 156us/step - loss: 0.3122 - mean_absolute_error: 0.3122 - val_loss: 0.3018 - val_mean_absolute_error: 0.3018\n",
      "Epoch 157/500\n",
      "928/928 [==============================] - 0s 139us/step - loss: 0.3131 - mean_absolute_error: 0.3131 - val_loss: 0.3030 - val_mean_absolute_error: 0.3030\n",
      "Epoch 158/500\n",
      "928/928 [==============================] - 0s 143us/step - loss: 0.3112 - mean_absolute_error: 0.3112 - val_loss: 0.3077 - val_mean_absolute_error: 0.3077\n",
      "Epoch 159/500\n",
      "928/928 [==============================] - 0s 148us/step - loss: 0.3117 - mean_absolute_error: 0.3117 - val_loss: 0.3026 - val_mean_absolute_error: 0.3026\n",
      "Epoch 160/500\n",
      "928/928 [==============================] - 0s 170us/step - loss: 0.3120 - mean_absolute_error: 0.3120 - val_loss: 0.3029 - val_mean_absolute_error: 0.3029\n",
      "Epoch 161/500\n",
      "928/928 [==============================] - 0s 196us/step - loss: 0.3123 - mean_absolute_error: 0.3123 - val_loss: 0.3064 - val_mean_absolute_error: 0.3064\n",
      "Epoch 162/500\n",
      "928/928 [==============================] - 0s 217us/step - loss: 0.3112 - mean_absolute_error: 0.3112 - val_loss: 0.3105 - val_mean_absolute_error: 0.3105\n",
      "Epoch 163/500\n",
      "928/928 [==============================] - 0s 172us/step - loss: 0.3111 - mean_absolute_error: 0.3111 - val_loss: 0.3033 - val_mean_absolute_error: 0.3033\n",
      "Epoch 164/500\n",
      "928/928 [==============================] - 0s 164us/step - loss: 0.3120 - mean_absolute_error: 0.3120 - val_loss: 0.3070 - val_mean_absolute_error: 0.3070\n",
      "Epoch 165/500\n",
      "928/928 [==============================] - 0s 157us/step - loss: 0.3117 - mean_absolute_error: 0.3117 - val_loss: 0.3018 - val_mean_absolute_error: 0.3018\n",
      "Epoch 166/500\n",
      "928/928 [==============================] - 0s 140us/step - loss: 0.3112 - mean_absolute_error: 0.3112 - val_loss: 0.3038 - val_mean_absolute_error: 0.3038\n",
      "Epoch 167/500\n",
      "928/928 [==============================] - 0s 175us/step - loss: 0.3116 - mean_absolute_error: 0.3116 - val_loss: 0.3063 - val_mean_absolute_error: 0.3063\n",
      "Epoch 168/500\n",
      "928/928 [==============================] - 0s 231us/step - loss: 0.3109 - mean_absolute_error: 0.3109 - val_loss: 0.3029 - val_mean_absolute_error: 0.3029\n",
      "Epoch 169/500\n",
      "928/928 [==============================] - 0s 148us/step - loss: 0.3117 - mean_absolute_error: 0.3117 - val_loss: 0.3029 - val_mean_absolute_error: 0.3029\n",
      "Epoch 170/500\n",
      "928/928 [==============================] - 0s 150us/step - loss: 0.3118 - mean_absolute_error: 0.3118 - val_loss: 0.3075 - val_mean_absolute_error: 0.3075\n",
      "Epoch 171/500\n",
      "928/928 [==============================] - 0s 146us/step - loss: 0.3136 - mean_absolute_error: 0.3136 - val_loss: 0.3116 - val_mean_absolute_error: 0.3116\n",
      "Epoch 172/500\n",
      "928/928 [==============================] - 0s 163us/step - loss: 0.3123 - mean_absolute_error: 0.3123 - val_loss: 0.3083 - val_mean_absolute_error: 0.3083\n",
      "Epoch 173/500\n",
      "928/928 [==============================] - 0s 200us/step - loss: 0.3146 - mean_absolute_error: 0.3146 - val_loss: 0.3054 - val_mean_absolute_error: 0.3054\n",
      "Epoch 174/500\n",
      "928/928 [==============================] - 0s 220us/step - loss: 0.3106 - mean_absolute_error: 0.3106 - val_loss: 0.3060 - val_mean_absolute_error: 0.3060\n",
      "Epoch 175/500\n",
      "928/928 [==============================] - 0s 136us/step - loss: 0.3115 - mean_absolute_error: 0.3115 - val_loss: 0.3031 - val_mean_absolute_error: 0.3031\n",
      "Epoch 176/500\n",
      "928/928 [==============================] - 0s 222us/step - loss: 0.3142 - mean_absolute_error: 0.3142 - val_loss: 0.3136 - val_mean_absolute_error: 0.3136\n",
      "Epoch 177/500\n",
      "928/928 [==============================] - 0s 187us/step - loss: 0.3132 - mean_absolute_error: 0.3132 - val_loss: 0.3019 - val_mean_absolute_error: 0.3019\n",
      "Epoch 178/500\n",
      "928/928 [==============================] - 0s 239us/step - loss: 0.3111 - mean_absolute_error: 0.3111 - val_loss: 0.3043 - val_mean_absolute_error: 0.3043\n",
      "Epoch 179/500\n",
      "928/928 [==============================] - 0s 168us/step - loss: 0.3116 - mean_absolute_error: 0.3116 - val_loss: 0.3019 - val_mean_absolute_error: 0.3019\n",
      "Epoch 180/500\n",
      "928/928 [==============================] - 0s 156us/step - loss: 0.3106 - mean_absolute_error: 0.3106 - val_loss: 0.3059 - val_mean_absolute_error: 0.3059\n",
      "Epoch 181/500\n",
      "928/928 [==============================] - 0s 143us/step - loss: 0.3127 - mean_absolute_error: 0.3127 - val_loss: 0.3027 - val_mean_absolute_error: 0.3027\n",
      "Epoch 182/500\n",
      "928/928 [==============================] - 0s 153us/step - loss: 0.3100 - mean_absolute_error: 0.3100 - val_loss: 0.3031 - val_mean_absolute_error: 0.3031\n",
      "Epoch 183/500\n",
      "928/928 [==============================] - 0s 135us/step - loss: 0.3179 - mean_absolute_error: 0.3179 - val_loss: 0.3050 - val_mean_absolute_error: 0.3050\n",
      "Epoch 184/500\n",
      "928/928 [==============================] - 0s 209us/step - loss: 0.3118 - mean_absolute_error: 0.3118 - val_loss: 0.3031 - val_mean_absolute_error: 0.3031\n",
      "Epoch 185/500\n",
      "928/928 [==============================] - 0s 177us/step - loss: 0.3119 - mean_absolute_error: 0.3119 - val_loss: 0.3018 - val_mean_absolute_error: 0.3018\n",
      "Epoch 186/500\n",
      "928/928 [==============================] - 0s 187us/step - loss: 0.3111 - mean_absolute_error: 0.3111 - val_loss: 0.3071 - val_mean_absolute_error: 0.3071\n",
      "Epoch 187/500\n",
      "928/928 [==============================] - 0s 146us/step - loss: 0.3105 - mean_absolute_error: 0.3105 - val_loss: 0.3042 - val_mean_absolute_error: 0.3042\n",
      "Epoch 188/500\n",
      "928/928 [==============================] - 0s 152us/step - loss: 0.3113 - mean_absolute_error: 0.3113 - val_loss: 0.3031 - val_mean_absolute_error: 0.3031\n",
      "Epoch 189/500\n",
      "928/928 [==============================] - 0s 169us/step - loss: 0.3112 - mean_absolute_error: 0.3112 - val_loss: 0.3028 - val_mean_absolute_error: 0.3028\n",
      "Epoch 190/500\n",
      "928/928 [==============================] - 0s 161us/step - loss: 0.3121 - mean_absolute_error: 0.3121 - val_loss: 0.3076 - val_mean_absolute_error: 0.3076\n",
      "Epoch 191/500\n",
      "928/928 [==============================] - 0s 157us/step - loss: 0.3114 - mean_absolute_error: 0.3114 - val_loss: 0.3018 - val_mean_absolute_error: 0.3018\n",
      "Epoch 192/500\n",
      "928/928 [==============================] - 0s 161us/step - loss: 0.3149 - mean_absolute_error: 0.3149 - val_loss: 0.3039 - val_mean_absolute_error: 0.3039\n",
      "Epoch 193/500\n",
      "928/928 [==============================] - 0s 159us/step - loss: 0.3110 - mean_absolute_error: 0.3110 - val_loss: 0.3029 - val_mean_absolute_error: 0.3029\n",
      "Epoch 194/500\n",
      "928/928 [==============================] - 0s 142us/step - loss: 0.3107 - mean_absolute_error: 0.3107 - val_loss: 0.3028 - val_mean_absolute_error: 0.3028\n",
      "Epoch 195/500\n",
      "928/928 [==============================] - 0s 154us/step - loss: 0.3150 - mean_absolute_error: 0.3150 - val_loss: 0.3027 - val_mean_absolute_error: 0.3027\n",
      "Epoch 196/500\n",
      "928/928 [==============================] - 0s 138us/step - loss: 0.3135 - mean_absolute_error: 0.3135 - val_loss: 0.3019 - val_mean_absolute_error: 0.3019\n",
      "Epoch 197/500\n",
      "928/928 [==============================] - 0s 157us/step - loss: 0.3131 - mean_absolute_error: 0.3131 - val_loss: 0.3021 - val_mean_absolute_error: 0.3021\n",
      "Epoch 198/500\n",
      "928/928 [==============================] - 0s 123us/step - loss: 0.3116 - mean_absolute_error: 0.3116 - val_loss: 0.3019 - val_mean_absolute_error: 0.3019\n",
      "Epoch 199/500\n",
      "928/928 [==============================] - 0s 145us/step - loss: 0.3115 - mean_absolute_error: 0.3115 - val_loss: 0.3018 - val_mean_absolute_error: 0.3018\n",
      "Epoch 200/500\n",
      "928/928 [==============================] - 0s 140us/step - loss: 0.3116 - mean_absolute_error: 0.3116 - val_loss: 0.3036 - val_mean_absolute_error: 0.3036\n",
      "Epoch 201/500\n",
      "928/928 [==============================] - 0s 150us/step - loss: 0.3109 - mean_absolute_error: 0.3109 - val_loss: 0.3095 - val_mean_absolute_error: 0.3095\n",
      "Epoch 202/500\n",
      "928/928 [==============================] - 0s 148us/step - loss: 0.3112 - mean_absolute_error: 0.3112 - val_loss: 0.3035 - val_mean_absolute_error: 0.3035\n",
      "Epoch 203/500\n",
      "928/928 [==============================] - 0s 146us/step - loss: 0.3111 - mean_absolute_error: 0.3111 - val_loss: 0.3057 - val_mean_absolute_error: 0.3057\n",
      "Epoch 204/500\n",
      "928/928 [==============================] - 0s 158us/step - loss: 0.3118 - mean_absolute_error: 0.3118 - val_loss: 0.3022 - val_mean_absolute_error: 0.3022\n",
      "Epoch 205/500\n",
      "928/928 [==============================] - 0s 204us/step - loss: 0.3126 - mean_absolute_error: 0.3126 - val_loss: 0.3023 - val_mean_absolute_error: 0.3023\n",
      "Epoch 206/500\n",
      "928/928 [==============================] - 0s 149us/step - loss: 0.3104 - mean_absolute_error: 0.3104 - val_loss: 0.3020 - val_mean_absolute_error: 0.3020\n",
      "Epoch 207/500\n",
      "928/928 [==============================] - 0s 196us/step - loss: 0.3133 - mean_absolute_error: 0.3133 - val_loss: 0.3028 - val_mean_absolute_error: 0.3028\n",
      "Epoch 208/500\n",
      "928/928 [==============================] - 0s 177us/step - loss: 0.3101 - mean_absolute_error: 0.3101 - val_loss: 0.3080 - val_mean_absolute_error: 0.3080\n",
      "Epoch 209/500\n",
      "928/928 [==============================] - 0s 164us/step - loss: 0.3150 - mean_absolute_error: 0.3150 - val_loss: 0.3038 - val_mean_absolute_error: 0.3038\n",
      "Epoch 210/500\n",
      "928/928 [==============================] - 0s 139us/step - loss: 0.3115 - mean_absolute_error: 0.3115 - val_loss: 0.3031 - val_mean_absolute_error: 0.3031\n",
      "Epoch 211/500\n",
      "928/928 [==============================] - 0s 153us/step - loss: 0.3122 - mean_absolute_error: 0.3122 - val_loss: 0.3019 - val_mean_absolute_error: 0.3019\n",
      "Epoch 212/500\n",
      "928/928 [==============================] - 0s 142us/step - loss: 0.3113 - mean_absolute_error: 0.3113 - val_loss: 0.3028 - val_mean_absolute_error: 0.3028\n",
      "Epoch 213/500\n",
      "928/928 [==============================] - 0s 148us/step - loss: 0.3115 - mean_absolute_error: 0.3115 - val_loss: 0.3018 - val_mean_absolute_error: 0.3018\n",
      "Epoch 214/500\n",
      "928/928 [==============================] - 0s 161us/step - loss: 0.3111 - mean_absolute_error: 0.3111 - val_loss: 0.3064 - val_mean_absolute_error: 0.3064\n",
      "Epoch 215/500\n",
      "928/928 [==============================] - 0s 139us/step - loss: 0.3110 - mean_absolute_error: 0.3110 - val_loss: 0.3025 - val_mean_absolute_error: 0.3025\n",
      "Epoch 216/500\n",
      "928/928 [==============================] - 0s 167us/step - loss: 0.3118 - mean_absolute_error: 0.3118 - val_loss: 0.3058 - val_mean_absolute_error: 0.3058\n",
      "Epoch 217/500\n",
      "928/928 [==============================] - 0s 124us/step - loss: 0.3110 - mean_absolute_error: 0.3110 - val_loss: 0.3036 - val_mean_absolute_error: 0.3036\n",
      "Epoch 218/500\n",
      "928/928 [==============================] - 0s 133us/step - loss: 0.3111 - mean_absolute_error: 0.3111 - val_loss: 0.3022 - val_mean_absolute_error: 0.3022\n",
      "Epoch 219/500\n",
      "928/928 [==============================] - 0s 141us/step - loss: 0.3138 - mean_absolute_error: 0.3138 - val_loss: 0.3019 - val_mean_absolute_error: 0.3019\n",
      "Epoch 220/500\n",
      "928/928 [==============================] - 0s 146us/step - loss: 0.3118 - mean_absolute_error: 0.3118 - val_loss: 0.3020 - val_mean_absolute_error: 0.3020\n",
      "Epoch 221/500\n",
      "928/928 [==============================] - 0s 220us/step - loss: 0.3130 - mean_absolute_error: 0.3130 - val_loss: 0.3055 - val_mean_absolute_error: 0.3055\n",
      "Epoch 222/500\n",
      "928/928 [==============================] - 0s 150us/step - loss: 0.3157 - mean_absolute_error: 0.3157 - val_loss: 0.3018 - val_mean_absolute_error: 0.3018\n",
      "Epoch 223/500\n",
      "928/928 [==============================] - 0s 148us/step - loss: 0.3121 - mean_absolute_error: 0.3121 - val_loss: 0.3029 - val_mean_absolute_error: 0.3029\n",
      "Epoch 224/500\n",
      "928/928 [==============================] - 0s 138us/step - loss: 0.3101 - mean_absolute_error: 0.3101 - val_loss: 0.3029 - val_mean_absolute_error: 0.3029\n",
      "Epoch 225/500\n",
      "928/928 [==============================] - 0s 231us/step - loss: 0.3137 - mean_absolute_error: 0.3137 - val_loss: 0.3047 - val_mean_absolute_error: 0.3047\n",
      "Epoch 226/500\n",
      "928/928 [==============================] - 0s 163us/step - loss: 0.3108 - mean_absolute_error: 0.3108 - val_loss: 0.3043 - val_mean_absolute_error: 0.3043\n",
      "Epoch 227/500\n",
      "928/928 [==============================] - 0s 207us/step - loss: 0.3115 - mean_absolute_error: 0.3115 - val_loss: 0.3044 - val_mean_absolute_error: 0.3044\n",
      "Epoch 228/500\n",
      "928/928 [==============================] - 0s 285us/step - loss: 0.3122 - mean_absolute_error: 0.3122 - val_loss: 0.3028 - val_mean_absolute_error: 0.3028\n",
      "Epoch 229/500\n",
      "928/928 [==============================] - 0s 264us/step - loss: 0.3136 - mean_absolute_error: 0.3136 - val_loss: 0.3038 - val_mean_absolute_error: 0.3038\n",
      "Epoch 230/500\n",
      "928/928 [==============================] - 0s 178us/step - loss: 0.3097 - mean_absolute_error: 0.3097 - val_loss: 0.3070 - val_mean_absolute_error: 0.3070\n",
      "Epoch 231/500\n",
      "928/928 [==============================] - 0s 189us/step - loss: 0.3126 - mean_absolute_error: 0.3126 - val_loss: 0.3020 - val_mean_absolute_error: 0.3020\n",
      "Epoch 232/500\n",
      "928/928 [==============================] - 0s 253us/step - loss: 0.3107 - mean_absolute_error: 0.3107 - val_loss: 0.3034 - val_mean_absolute_error: 0.3034\n",
      "Epoch 233/500\n",
      "928/928 [==============================] - 0s 164us/step - loss: 0.3089 - mean_absolute_error: 0.3089 - val_loss: 0.3051 - val_mean_absolute_error: 0.3051\n",
      "Epoch 234/500\n",
      "928/928 [==============================] - 0s 139us/step - loss: 0.3167 - mean_absolute_error: 0.3167 - val_loss: 0.3050 - val_mean_absolute_error: 0.3050\n",
      "Epoch 235/500\n",
      "928/928 [==============================] - 0s 145us/step - loss: 0.3148 - mean_absolute_error: 0.3148 - val_loss: 0.3117 - val_mean_absolute_error: 0.3117\n",
      "Epoch 236/500\n",
      "928/928 [==============================] - 0s 160us/step - loss: 0.3113 - mean_absolute_error: 0.3113 - val_loss: 0.3031 - val_mean_absolute_error: 0.3031\n",
      "Epoch 237/500\n",
      "928/928 [==============================] - 0s 199us/step - loss: 0.3104 - mean_absolute_error: 0.3104 - val_loss: 0.3022 - val_mean_absolute_error: 0.3022\n",
      "Epoch 238/500\n",
      "928/928 [==============================] - 0s 166us/step - loss: 0.3126 - mean_absolute_error: 0.3126 - val_loss: 0.3042 - val_mean_absolute_error: 0.3042\n",
      "Epoch 239/500\n",
      "928/928 [==============================] - 0s 139us/step - loss: 0.3148 - mean_absolute_error: 0.3148 - val_loss: 0.3021 - val_mean_absolute_error: 0.3021\n",
      "Epoch 240/500\n",
      "928/928 [==============================] - 0s 178us/step - loss: 0.3100 - mean_absolute_error: 0.3100 - val_loss: 0.3023 - val_mean_absolute_error: 0.3023\n",
      "Epoch 241/500\n",
      "928/928 [==============================] - 0s 175us/step - loss: 0.3110 - mean_absolute_error: 0.3110 - val_loss: 0.3022 - val_mean_absolute_error: 0.3022\n",
      "Epoch 242/500\n",
      "928/928 [==============================] - 0s 155us/step - loss: 0.3107 - mean_absolute_error: 0.3107 - val_loss: 0.3043 - val_mean_absolute_error: 0.3043\n",
      "Epoch 243/500\n",
      "928/928 [==============================] - 0s 146us/step - loss: 0.3122 - mean_absolute_error: 0.3122 - val_loss: 0.3041 - val_mean_absolute_error: 0.3041\n",
      "Epoch 244/500\n",
      "928/928 [==============================] - 0s 145us/step - loss: 0.3107 - mean_absolute_error: 0.3107 - val_loss: 0.3030 - val_mean_absolute_error: 0.3030\n",
      "Epoch 245/500\n",
      "928/928 [==============================] - 0s 167us/step - loss: 0.3103 - mean_absolute_error: 0.3103 - val_loss: 0.3023 - val_mean_absolute_error: 0.3023\n",
      "Epoch 246/500\n",
      "928/928 [==============================] - 0s 202us/step - loss: 0.3115 - mean_absolute_error: 0.3115 - val_loss: 0.3022 - val_mean_absolute_error: 0.3022\n",
      "Epoch 247/500\n",
      "928/928 [==============================] - 0s 184us/step - loss: 0.3115 - mean_absolute_error: 0.3115 - val_loss: 0.3019 - val_mean_absolute_error: 0.3019\n",
      "Epoch 248/500\n",
      "928/928 [==============================] - 0s 192us/step - loss: 0.3117 - mean_absolute_error: 0.3117 - val_loss: 0.3050 - val_mean_absolute_error: 0.3050\n",
      "Epoch 249/500\n",
      "928/928 [==============================] - 0s 171us/step - loss: 0.3111 - mean_absolute_error: 0.3111 - val_loss: 0.3040 - val_mean_absolute_error: 0.3040\n",
      "Epoch 250/500\n",
      "928/928 [==============================] - 0s 141us/step - loss: 0.3112 - mean_absolute_error: 0.3112 - val_loss: 0.3023 - val_mean_absolute_error: 0.3023\n",
      "Epoch 251/500\n",
      "928/928 [==============================] - 0s 150us/step - loss: 0.3102 - mean_absolute_error: 0.3102 - val_loss: 0.3061 - val_mean_absolute_error: 0.3061\n",
      "Epoch 252/500\n",
      "928/928 [==============================] - 0s 169us/step - loss: 0.3110 - mean_absolute_error: 0.3110 - val_loss: 0.3066 - val_mean_absolute_error: 0.3066\n",
      "Epoch 253/500\n",
      "928/928 [==============================] - 0s 135us/step - loss: 0.3121 - mean_absolute_error: 0.3121 - val_loss: 0.3035 - val_mean_absolute_error: 0.3035\n",
      "Epoch 254/500\n",
      "928/928 [==============================] - 0s 142us/step - loss: 0.3120 - mean_absolute_error: 0.3120 - val_loss: 0.3031 - val_mean_absolute_error: 0.3031\n",
      "Epoch 255/500\n",
      "928/928 [==============================] - 0s 163us/step - loss: 0.3116 - mean_absolute_error: 0.3116 - val_loss: 0.3027 - val_mean_absolute_error: 0.3027\n",
      "Epoch 256/500\n",
      "928/928 [==============================] - 0s 146us/step - loss: 0.3107 - mean_absolute_error: 0.3107 - val_loss: 0.3022 - val_mean_absolute_error: 0.3022\n",
      "Epoch 257/500\n",
      "928/928 [==============================] - 0s 157us/step - loss: 0.3104 - mean_absolute_error: 0.3104 - val_loss: 0.3018 - val_mean_absolute_error: 0.3018\n",
      "Epoch 258/500\n",
      "928/928 [==============================] - 0s 170us/step - loss: 0.3134 - mean_absolute_error: 0.3134 - val_loss: 0.3024 - val_mean_absolute_error: 0.3024\n",
      "Epoch 259/500\n",
      "928/928 [==============================] - 0s 148us/step - loss: 0.3132 - mean_absolute_error: 0.3132 - val_loss: 0.3105 - val_mean_absolute_error: 0.3105\n",
      "Epoch 260/500\n",
      "928/928 [==============================] - 0s 155us/step - loss: 0.3132 - mean_absolute_error: 0.3132 - val_loss: 0.3182 - val_mean_absolute_error: 0.3182\n",
      "Epoch 261/500\n",
      "928/928 [==============================] - 0s 147us/step - loss: 0.3129 - mean_absolute_error: 0.3129 - val_loss: 0.3072 - val_mean_absolute_error: 0.3072\n",
      "Epoch 262/500\n",
      "928/928 [==============================] - 0s 176us/step - loss: 0.3118 - mean_absolute_error: 0.3118 - val_loss: 0.3045 - val_mean_absolute_error: 0.3045\n",
      "Epoch 263/500\n",
      "928/928 [==============================] - 0s 159us/step - loss: 0.3097 - mean_absolute_error: 0.3097 - val_loss: 0.3046 - val_mean_absolute_error: 0.3046\n",
      "Epoch 264/500\n",
      "928/928 [==============================] - 0s 181us/step - loss: 0.3106 - mean_absolute_error: 0.3106 - val_loss: 0.3091 - val_mean_absolute_error: 0.3091\n",
      "Epoch 265/500\n",
      "928/928 [==============================] - 0s 163us/step - loss: 0.3138 - mean_absolute_error: 0.3138 - val_loss: 0.3051 - val_mean_absolute_error: 0.3051\n",
      "Epoch 266/500\n",
      "928/928 [==============================] - 0s 155us/step - loss: 0.3105 - mean_absolute_error: 0.3105 - val_loss: 0.3025 - val_mean_absolute_error: 0.3025\n",
      "Epoch 267/500\n",
      "928/928 [==============================] - 0s 156us/step - loss: 0.3110 - mean_absolute_error: 0.3110 - val_loss: 0.3022 - val_mean_absolute_error: 0.3022\n",
      "Epoch 268/500\n",
      "928/928 [==============================] - 0s 161us/step - loss: 0.3126 - mean_absolute_error: 0.3126 - val_loss: 0.3025 - val_mean_absolute_error: 0.3025\n",
      "Epoch 269/500\n",
      "928/928 [==============================] - 0s 138us/step - loss: 0.3130 - mean_absolute_error: 0.3130 - val_loss: 0.3021 - val_mean_absolute_error: 0.3021\n",
      "Epoch 270/500\n",
      "928/928 [==============================] - 0s 131us/step - loss: 0.3113 - mean_absolute_error: 0.3113 - val_loss: 0.3054 - val_mean_absolute_error: 0.3054\n",
      "Epoch 271/500\n",
      "928/928 [==============================] - 0s 152us/step - loss: 0.3134 - mean_absolute_error: 0.3134 - val_loss: 0.3020 - val_mean_absolute_error: 0.3020\n",
      "Epoch 272/500\n",
      "928/928 [==============================] - 0s 143us/step - loss: 0.3113 - mean_absolute_error: 0.3113 - val_loss: 0.3033 - val_mean_absolute_error: 0.3033\n",
      "Epoch 273/500\n",
      "928/928 [==============================] - 0s 147us/step - loss: 0.3104 - mean_absolute_error: 0.3104 - val_loss: 0.3025 - val_mean_absolute_error: 0.3025\n",
      "Epoch 274/500\n",
      "928/928 [==============================] - 0s 136us/step - loss: 0.3120 - mean_absolute_error: 0.3120 - val_loss: 0.3044 - val_mean_absolute_error: 0.3044\n",
      "Epoch 275/500\n",
      "928/928 [==============================] - 0s 142us/step - loss: 0.3136 - mean_absolute_error: 0.3136 - val_loss: 0.3070 - val_mean_absolute_error: 0.3070\n",
      "Epoch 276/500\n",
      "928/928 [==============================] - 0s 142us/step - loss: 0.3106 - mean_absolute_error: 0.3106 - val_loss: 0.3018 - val_mean_absolute_error: 0.3018\n",
      "Epoch 277/500\n",
      "928/928 [==============================] - 0s 149us/step - loss: 0.3103 - mean_absolute_error: 0.3103 - val_loss: 0.3022 - val_mean_absolute_error: 0.3022\n",
      "Epoch 278/500\n",
      "928/928 [==============================] - 0s 230us/step - loss: 0.3125 - mean_absolute_error: 0.3125 - val_loss: 0.3037 - val_mean_absolute_error: 0.3037\n",
      "Epoch 279/500\n",
      "928/928 [==============================] - 0s 175us/step - loss: 0.3132 - mean_absolute_error: 0.3132 - val_loss: 0.3037 - val_mean_absolute_error: 0.3037\n",
      "Epoch 280/500\n",
      "928/928 [==============================] - 0s 153us/step - loss: 0.3109 - mean_absolute_error: 0.3109 - val_loss: 0.3019 - val_mean_absolute_error: 0.3019\n",
      "Epoch 281/500\n",
      "928/928 [==============================] - 0s 144us/step - loss: 0.3106 - mean_absolute_error: 0.3106 - val_loss: 0.3064 - val_mean_absolute_error: 0.3064\n",
      "Epoch 282/500\n",
      "928/928 [==============================] - 0s 198us/step - loss: 0.3129 - mean_absolute_error: 0.3129 - val_loss: 0.3019 - val_mean_absolute_error: 0.3019\n",
      "Epoch 283/500\n",
      "928/928 [==============================] - 0s 159us/step - loss: 0.3121 - mean_absolute_error: 0.3121 - val_loss: 0.3151 - val_mean_absolute_error: 0.3151\n",
      "Epoch 284/500\n",
      "928/928 [==============================] - 0s 163us/step - loss: 0.3112 - mean_absolute_error: 0.3112 - val_loss: 0.3021 - val_mean_absolute_error: 0.3021\n",
      "Epoch 285/500\n",
      "928/928 [==============================] - 0s 144us/step - loss: 0.3109 - mean_absolute_error: 0.3109 - val_loss: 0.3040 - val_mean_absolute_error: 0.3040\n",
      "Epoch 286/500\n",
      "928/928 [==============================] - 0s 145us/step - loss: 0.3109 - mean_absolute_error: 0.3109 - val_loss: 0.3021 - val_mean_absolute_error: 0.3021\n",
      "Epoch 287/500\n",
      "928/928 [==============================] - 0s 128us/step - loss: 0.3119 - mean_absolute_error: 0.3119 - val_loss: 0.3020 - val_mean_absolute_error: 0.3020\n",
      "Epoch 288/500\n",
      "928/928 [==============================] - 0s 130us/step - loss: 0.3116 - mean_absolute_error: 0.3116 - val_loss: 0.3020 - val_mean_absolute_error: 0.3020\n",
      "Epoch 289/500\n",
      "928/928 [==============================] - 0s 134us/step - loss: 0.3126 - mean_absolute_error: 0.3126 - val_loss: 0.3019 - val_mean_absolute_error: 0.3019\n",
      "Epoch 290/500\n",
      "928/928 [==============================] - 0s 195us/step - loss: 0.3107 - mean_absolute_error: 0.3107 - val_loss: 0.3073 - val_mean_absolute_error: 0.3073\n",
      "Epoch 291/500\n",
      "928/928 [==============================] - 0s 224us/step - loss: 0.3134 - mean_absolute_error: 0.3134 - val_loss: 0.3093 - val_mean_absolute_error: 0.3093\n",
      "Epoch 292/500\n",
      "928/928 [==============================] - 0s 186us/step - loss: 0.3113 - mean_absolute_error: 0.3113 - val_loss: 0.3018 - val_mean_absolute_error: 0.3018\n",
      "Epoch 293/500\n",
      "928/928 [==============================] - 0s 182us/step - loss: 0.3101 - mean_absolute_error: 0.3101 - val_loss: 0.3034 - val_mean_absolute_error: 0.3034\n",
      "Epoch 294/500\n",
      "928/928 [==============================] - 0s 162us/step - loss: 0.3112 - mean_absolute_error: 0.3112 - val_loss: 0.3019 - val_mean_absolute_error: 0.3019\n",
      "Epoch 295/500\n",
      "928/928 [==============================] - 0s 208us/step - loss: 0.3100 - mean_absolute_error: 0.3100 - val_loss: 0.3083 - val_mean_absolute_error: 0.3083\n",
      "Epoch 296/500\n",
      "928/928 [==============================] - 0s 236us/step - loss: 0.3186 - mean_absolute_error: 0.3186 - val_loss: 0.3031 - val_mean_absolute_error: 0.3031\n",
      "Epoch 297/500\n",
      "928/928 [==============================] - 0s 480us/step - loss: 0.3121 - mean_absolute_error: 0.3121 - val_loss: 0.3056 - val_mean_absolute_error: 0.3056\n",
      "Epoch 298/500\n",
      "928/928 [==============================] - 0s 191us/step - loss: 0.3122 - mean_absolute_error: 0.3122 - val_loss: 0.3053 - val_mean_absolute_error: 0.3053\n",
      "Epoch 299/500\n",
      "928/928 [==============================] - 0s 150us/step - loss: 0.3126 - mean_absolute_error: 0.3126 - val_loss: 0.3018 - val_mean_absolute_error: 0.3018\n",
      "Epoch 300/500\n",
      "928/928 [==============================] - 0s 151us/step - loss: 0.3118 - mean_absolute_error: 0.3118 - val_loss: 0.3056 - val_mean_absolute_error: 0.3056\n",
      "Epoch 301/500\n",
      "928/928 [==============================] - 0s 195us/step - loss: 0.3131 - mean_absolute_error: 0.3131 - val_loss: 0.3020 - val_mean_absolute_error: 0.3020\n",
      "Epoch 302/500\n",
      "928/928 [==============================] - 0s 127us/step - loss: 0.3109 - mean_absolute_error: 0.3109 - val_loss: 0.3057 - val_mean_absolute_error: 0.3057\n",
      "Epoch 303/500\n",
      "928/928 [==============================] - 0s 176us/step - loss: 0.3112 - mean_absolute_error: 0.3112 - val_loss: 0.3023 - val_mean_absolute_error: 0.3023\n",
      "Epoch 304/500\n",
      "928/928 [==============================] - 0s 143us/step - loss: 0.3126 - mean_absolute_error: 0.3126 - val_loss: 0.3109 - val_mean_absolute_error: 0.3109\n",
      "Epoch 305/500\n",
      "928/928 [==============================] - 0s 167us/step - loss: 0.3124 - mean_absolute_error: 0.3124 - val_loss: 0.3128 - val_mean_absolute_error: 0.3128\n",
      "Epoch 306/500\n",
      "928/928 [==============================] - 0s 181us/step - loss: 0.3119 - mean_absolute_error: 0.3119 - val_loss: 0.3104 - val_mean_absolute_error: 0.3104\n",
      "Epoch 307/500\n",
      "928/928 [==============================] - 0s 162us/step - loss: 0.3177 - mean_absolute_error: 0.3177 - val_loss: 0.3019 - val_mean_absolute_error: 0.3019\n",
      "Epoch 308/500\n",
      "928/928 [==============================] - 0s 170us/step - loss: 0.3096 - mean_absolute_error: 0.3096 - val_loss: 0.3089 - val_mean_absolute_error: 0.3089\n",
      "Epoch 309/500\n",
      "928/928 [==============================] - 0s 204us/step - loss: 0.3130 - mean_absolute_error: 0.3130 - val_loss: 0.3104 - val_mean_absolute_error: 0.3104\n",
      "Epoch 310/500\n",
      "928/928 [==============================] - 0s 145us/step - loss: 0.3152 - mean_absolute_error: 0.3152 - val_loss: 0.3039 - val_mean_absolute_error: 0.3039\n",
      "Epoch 311/500\n",
      "928/928 [==============================] - 0s 190us/step - loss: 0.3106 - mean_absolute_error: 0.3106 - val_loss: 0.3022 - val_mean_absolute_error: 0.3022\n",
      "Epoch 312/500\n",
      "928/928 [==============================] - 0s 221us/step - loss: 0.3122 - mean_absolute_error: 0.3122 - val_loss: 0.3021 - val_mean_absolute_error: 0.3021\n",
      "Epoch 313/500\n",
      "928/928 [==============================] - 0s 193us/step - loss: 0.3149 - mean_absolute_error: 0.3149 - val_loss: 0.3040 - val_mean_absolute_error: 0.3040\n",
      "Epoch 314/500\n",
      "928/928 [==============================] - 0s 190us/step - loss: 0.3096 - mean_absolute_error: 0.3096 - val_loss: 0.3025 - val_mean_absolute_error: 0.3025\n",
      "Epoch 315/500\n",
      "928/928 [==============================] - 0s 157us/step - loss: 0.3110 - mean_absolute_error: 0.3110 - val_loss: 0.3022 - val_mean_absolute_error: 0.3022\n",
      "Epoch 316/500\n",
      "928/928 [==============================] - 0s 182us/step - loss: 0.3115 - mean_absolute_error: 0.3115 - val_loss: 0.3064 - val_mean_absolute_error: 0.3064\n",
      "Epoch 317/500\n",
      "928/928 [==============================] - 0s 154us/step - loss: 0.3115 - mean_absolute_error: 0.3115 - val_loss: 0.3019 - val_mean_absolute_error: 0.3019\n",
      "Epoch 318/500\n",
      "928/928 [==============================] - 0s 150us/step - loss: 0.3096 - mean_absolute_error: 0.3096 - val_loss: 0.3041 - val_mean_absolute_error: 0.3041\n",
      "Epoch 319/500\n",
      "928/928 [==============================] - 0s 136us/step - loss: 0.3134 - mean_absolute_error: 0.3134 - val_loss: 0.3047 - val_mean_absolute_error: 0.3047\n",
      "Epoch 320/500\n",
      "928/928 [==============================] - 0s 157us/step - loss: 0.3136 - mean_absolute_error: 0.3136 - val_loss: 0.3297 - val_mean_absolute_error: 0.3297\n",
      "Epoch 321/500\n",
      "928/928 [==============================] - 0s 143us/step - loss: 0.3140 - mean_absolute_error: 0.3140 - val_loss: 0.3038 - val_mean_absolute_error: 0.3038\n",
      "Epoch 322/500\n",
      "928/928 [==============================] - 0s 138us/step - loss: 0.3132 - mean_absolute_error: 0.3132 - val_loss: 0.3032 - val_mean_absolute_error: 0.3032\n",
      "Epoch 323/500\n",
      "928/928 [==============================] - 0s 140us/step - loss: 0.3119 - mean_absolute_error: 0.3119 - val_loss: 0.3023 - val_mean_absolute_error: 0.3023\n",
      "Epoch 324/500\n",
      "928/928 [==============================] - 0s 153us/step - loss: 0.3106 - mean_absolute_error: 0.3106 - val_loss: 0.3054 - val_mean_absolute_error: 0.3054\n",
      "Epoch 325/500\n",
      "928/928 [==============================] - 0s 144us/step - loss: 0.3118 - mean_absolute_error: 0.3118 - val_loss: 0.3041 - val_mean_absolute_error: 0.3041\n",
      "Epoch 326/500\n",
      "928/928 [==============================] - 0s 157us/step - loss: 0.3099 - mean_absolute_error: 0.3099 - val_loss: 0.3038 - val_mean_absolute_error: 0.3038\n",
      "Epoch 327/500\n",
      "928/928 [==============================] - 0s 234us/step - loss: 0.3109 - mean_absolute_error: 0.3109 - val_loss: 0.3018 - val_mean_absolute_error: 0.3018\n",
      "Epoch 328/500\n",
      "928/928 [==============================] - 0s 169us/step - loss: 0.3113 - mean_absolute_error: 0.3113 - val_loss: 0.3074 - val_mean_absolute_error: 0.3074\n",
      "Epoch 329/500\n",
      "928/928 [==============================] - 0s 150us/step - loss: 0.3175 - mean_absolute_error: 0.3175 - val_loss: 0.3048 - val_mean_absolute_error: 0.3048\n",
      "Epoch 330/500\n",
      "928/928 [==============================] - 0s 138us/step - loss: 0.3119 - mean_absolute_error: 0.3119 - val_loss: 0.3071 - val_mean_absolute_error: 0.3071\n",
      "Epoch 331/500\n",
      "928/928 [==============================] - 0s 149us/step - loss: 0.3121 - mean_absolute_error: 0.3121 - val_loss: 0.3037 - val_mean_absolute_error: 0.3037\n",
      "Epoch 332/500\n",
      "928/928 [==============================] - 0s 202us/step - loss: 0.3125 - mean_absolute_error: 0.3125 - val_loss: 0.3033 - val_mean_absolute_error: 0.3033\n",
      "Epoch 333/500\n",
      "928/928 [==============================] - 0s 199us/step - loss: 0.3101 - mean_absolute_error: 0.3101 - val_loss: 0.3037 - val_mean_absolute_error: 0.3037\n",
      "Epoch 334/500\n",
      "928/928 [==============================] - 0s 161us/step - loss: 0.3103 - mean_absolute_error: 0.3103 - val_loss: 0.3018 - val_mean_absolute_error: 0.3018\n",
      "Epoch 335/500\n",
      "928/928 [==============================] - 0s 163us/step - loss: 0.3110 - mean_absolute_error: 0.3110 - val_loss: 0.3175 - val_mean_absolute_error: 0.3175\n",
      "Epoch 336/500\n",
      "928/928 [==============================] - 0s 141us/step - loss: 0.3116 - mean_absolute_error: 0.3116 - val_loss: 0.3025 - val_mean_absolute_error: 0.3025\n",
      "Epoch 337/500\n",
      "928/928 [==============================] - 0s 156us/step - loss: 0.3107 - mean_absolute_error: 0.3107 - val_loss: 0.3018 - val_mean_absolute_error: 0.3018\n",
      "Epoch 338/500\n",
      "928/928 [==============================] - 0s 149us/step - loss: 0.3113 - mean_absolute_error: 0.3113 - val_loss: 0.3025 - val_mean_absolute_error: 0.3025\n",
      "Epoch 339/500\n",
      "928/928 [==============================] - 0s 184us/step - loss: 0.3114 - mean_absolute_error: 0.3114 - val_loss: 0.3022 - val_mean_absolute_error: 0.3022\n",
      "Epoch 340/500\n",
      "928/928 [==============================] - 0s 147us/step - loss: 0.3114 - mean_absolute_error: 0.3114 - val_loss: 0.3089 - val_mean_absolute_error: 0.3089\n",
      "Epoch 341/500\n",
      "928/928 [==============================] - 0s 159us/step - loss: 0.3123 - mean_absolute_error: 0.3123 - val_loss: 0.3082 - val_mean_absolute_error: 0.3082\n",
      "Epoch 342/500\n",
      "928/928 [==============================] - 0s 169us/step - loss: 0.3125 - mean_absolute_error: 0.3125 - val_loss: 0.3031 - val_mean_absolute_error: 0.3031\n",
      "Epoch 343/500\n",
      "928/928 [==============================] - 0s 182us/step - loss: 0.3113 - mean_absolute_error: 0.3113 - val_loss: 0.3027 - val_mean_absolute_error: 0.3027\n",
      "Epoch 344/500\n",
      "928/928 [==============================] - 0s 154us/step - loss: 0.3110 - mean_absolute_error: 0.3110 - val_loss: 0.3072 - val_mean_absolute_error: 0.3072\n",
      "Epoch 345/500\n",
      "928/928 [==============================] - 0s 146us/step - loss: 0.3122 - mean_absolute_error: 0.3122 - val_loss: 0.3018 - val_mean_absolute_error: 0.3018\n",
      "Epoch 346/500\n",
      "928/928 [==============================] - 0s 176us/step - loss: 0.3148 - mean_absolute_error: 0.3148 - val_loss: 0.3024 - val_mean_absolute_error: 0.3024\n",
      "Epoch 347/500\n",
      "928/928 [==============================] - 0s 178us/step - loss: 0.3159 - mean_absolute_error: 0.3159 - val_loss: 0.3067 - val_mean_absolute_error: 0.3067\n",
      "Epoch 348/500\n",
      "928/928 [==============================] - 0s 198us/step - loss: 0.3123 - mean_absolute_error: 0.3123 - val_loss: 0.3019 - val_mean_absolute_error: 0.3019\n",
      "Epoch 349/500\n",
      "928/928 [==============================] - 0s 153us/step - loss: 0.3111 - mean_absolute_error: 0.3111 - val_loss: 0.3047 - val_mean_absolute_error: 0.3047\n",
      "Epoch 350/500\n",
      "928/928 [==============================] - 0s 148us/step - loss: 0.3116 - mean_absolute_error: 0.3116 - val_loss: 0.3114 - val_mean_absolute_error: 0.3114\n",
      "Epoch 351/500\n",
      "928/928 [==============================] - 0s 162us/step - loss: 0.3145 - mean_absolute_error: 0.3145 - val_loss: 0.3085 - val_mean_absolute_error: 0.3085\n",
      "Epoch 352/500\n",
      "928/928 [==============================] - 0s 185us/step - loss: 0.3109 - mean_absolute_error: 0.3109 - val_loss: 0.3055 - val_mean_absolute_error: 0.3055\n",
      "Epoch 353/500\n",
      "928/928 [==============================] - 0s 145us/step - loss: 0.3118 - mean_absolute_error: 0.3118 - val_loss: 0.3042 - val_mean_absolute_error: 0.3042\n",
      "Epoch 354/500\n",
      "928/928 [==============================] - 0s 154us/step - loss: 0.3120 - mean_absolute_error: 0.3120 - val_loss: 0.3048 - val_mean_absolute_error: 0.3048\n",
      "Epoch 355/500\n",
      "928/928 [==============================] - 0s 138us/step - loss: 0.3100 - mean_absolute_error: 0.3100 - val_loss: 0.3116 - val_mean_absolute_error: 0.3116\n",
      "Epoch 356/500\n",
      "928/928 [==============================] - 0s 134us/step - loss: 0.3125 - mean_absolute_error: 0.3125 - val_loss: 0.3054 - val_mean_absolute_error: 0.3054\n",
      "Epoch 357/500\n",
      "928/928 [==============================] - 0s 198us/step - loss: 0.3110 - mean_absolute_error: 0.3110 - val_loss: 0.3021 - val_mean_absolute_error: 0.3021\n",
      "Epoch 358/500\n",
      "928/928 [==============================] - 0s 196us/step - loss: 0.3116 - mean_absolute_error: 0.3116 - val_loss: 0.3019 - val_mean_absolute_error: 0.3019\n",
      "Epoch 359/500\n",
      "928/928 [==============================] - 0s 215us/step - loss: 0.3135 - mean_absolute_error: 0.3135 - val_loss: 0.3021 - val_mean_absolute_error: 0.3021\n",
      "Epoch 360/500\n",
      "928/928 [==============================] - 0s 149us/step - loss: 0.3111 - mean_absolute_error: 0.3111 - val_loss: 0.3019 - val_mean_absolute_error: 0.3019\n",
      "Epoch 361/500\n",
      "928/928 [==============================] - 0s 187us/step - loss: 0.3100 - mean_absolute_error: 0.3100 - val_loss: 0.3024 - val_mean_absolute_error: 0.3024\n",
      "Epoch 362/500\n",
      "928/928 [==============================] - 0s 178us/step - loss: 0.3121 - mean_absolute_error: 0.3121 - val_loss: 0.3038 - val_mean_absolute_error: 0.3038\n",
      "Epoch 363/500\n",
      "928/928 [==============================] - 0s 133us/step - loss: 0.3107 - mean_absolute_error: 0.3107 - val_loss: 0.3050 - val_mean_absolute_error: 0.3050\n",
      "Epoch 364/500\n",
      "928/928 [==============================] - 0s 149us/step - loss: 0.3109 - mean_absolute_error: 0.3109 - val_loss: 0.3066 - val_mean_absolute_error: 0.3066\n",
      "Epoch 365/500\n",
      "928/928 [==============================] - 0s 248us/step - loss: 0.3124 - mean_absolute_error: 0.3124 - val_loss: 0.3019 - val_mean_absolute_error: 0.3019\n",
      "Epoch 366/500\n",
      "928/928 [==============================] - 0s 150us/step - loss: 0.3130 - mean_absolute_error: 0.3130 - val_loss: 0.3020 - val_mean_absolute_error: 0.3020\n",
      "Epoch 367/500\n",
      "928/928 [==============================] - 0s 188us/step - loss: 0.3106 - mean_absolute_error: 0.3106 - val_loss: 0.3043 - val_mean_absolute_error: 0.3043\n",
      "Epoch 368/500\n",
      "928/928 [==============================] - 0s 142us/step - loss: 0.3113 - mean_absolute_error: 0.3113 - val_loss: 0.3047 - val_mean_absolute_error: 0.3047\n",
      "Epoch 369/500\n",
      "928/928 [==============================] - 0s 152us/step - loss: 0.3114 - mean_absolute_error: 0.3114 - val_loss: 0.3021 - val_mean_absolute_error: 0.3021\n",
      "Epoch 370/500\n",
      "928/928 [==============================] - 0s 153us/step - loss: 0.3104 - mean_absolute_error: 0.3104 - val_loss: 0.3029 - val_mean_absolute_error: 0.3029\n",
      "Epoch 371/500\n",
      "928/928 [==============================] - 0s 166us/step - loss: 0.3140 - mean_absolute_error: 0.3140 - val_loss: 0.3154 - val_mean_absolute_error: 0.3154\n",
      "Epoch 372/500\n",
      "928/928 [==============================] - 0s 134us/step - loss: 0.3115 - mean_absolute_error: 0.3115 - val_loss: 0.3019 - val_mean_absolute_error: 0.3019\n",
      "Epoch 373/500\n",
      "928/928 [==============================] - 0s 135us/step - loss: 0.3105 - mean_absolute_error: 0.3105 - val_loss: 0.3019 - val_mean_absolute_error: 0.3019\n",
      "Epoch 374/500\n",
      "928/928 [==============================] - 0s 152us/step - loss: 0.3108 - mean_absolute_error: 0.3108 - val_loss: 0.3027 - val_mean_absolute_error: 0.3027\n",
      "Epoch 375/500\n",
      "928/928 [==============================] - 0s 134us/step - loss: 0.3111 - mean_absolute_error: 0.3111 - val_loss: 0.3026 - val_mean_absolute_error: 0.3026\n",
      "Epoch 376/500\n",
      "928/928 [==============================] - 0s 197us/step - loss: 0.3113 - mean_absolute_error: 0.3113 - val_loss: 0.3084 - val_mean_absolute_error: 0.3084\n",
      "Epoch 377/500\n",
      "928/928 [==============================] - 0s 162us/step - loss: 0.3104 - mean_absolute_error: 0.3104 - val_loss: 0.3245 - val_mean_absolute_error: 0.3245\n",
      "Epoch 378/500\n",
      "928/928 [==============================] - 0s 164us/step - loss: 0.3150 - mean_absolute_error: 0.3150 - val_loss: 0.3073 - val_mean_absolute_error: 0.3073\n",
      "Epoch 379/500\n",
      "928/928 [==============================] - 0s 145us/step - loss: 0.3114 - mean_absolute_error: 0.3114 - val_loss: 0.3024 - val_mean_absolute_error: 0.3024\n",
      "Epoch 380/500\n",
      "928/928 [==============================] - 0s 130us/step - loss: 0.3104 - mean_absolute_error: 0.3104 - val_loss: 0.3020 - val_mean_absolute_error: 0.3020\n",
      "Epoch 381/500\n",
      "928/928 [==============================] - 0s 167us/step - loss: 0.3103 - mean_absolute_error: 0.3103 - val_loss: 0.3034 - val_mean_absolute_error: 0.3034\n",
      "Epoch 382/500\n",
      "928/928 [==============================] - 0s 154us/step - loss: 0.3113 - mean_absolute_error: 0.3113 - val_loss: 0.3095 - val_mean_absolute_error: 0.3095\n",
      "Epoch 383/500\n",
      "928/928 [==============================] - 0s 130us/step - loss: 0.3137 - mean_absolute_error: 0.3137 - val_loss: 0.3073 - val_mean_absolute_error: 0.3073\n",
      "Epoch 384/500\n",
      "928/928 [==============================] - 0s 158us/step - loss: 0.3117 - mean_absolute_error: 0.3117 - val_loss: 0.3044 - val_mean_absolute_error: 0.3044\n",
      "Epoch 385/500\n",
      "928/928 [==============================] - 0s 136us/step - loss: 0.3123 - mean_absolute_error: 0.3123 - val_loss: 0.3028 - val_mean_absolute_error: 0.3028\n",
      "Epoch 386/500\n",
      "928/928 [==============================] - 0s 156us/step - loss: 0.3110 - mean_absolute_error: 0.3110 - val_loss: 0.3037 - val_mean_absolute_error: 0.3037\n",
      "Epoch 387/500\n",
      "928/928 [==============================] - 0s 134us/step - loss: 0.3109 - mean_absolute_error: 0.3109 - val_loss: 0.3018 - val_mean_absolute_error: 0.3018\n",
      "Epoch 388/500\n",
      "928/928 [==============================] - 0s 157us/step - loss: 0.3118 - mean_absolute_error: 0.3118 - val_loss: 0.3028 - val_mean_absolute_error: 0.3028\n",
      "Epoch 389/500\n",
      "928/928 [==============================] - 0s 159us/step - loss: 0.3125 - mean_absolute_error: 0.3125 - val_loss: 0.3053 - val_mean_absolute_error: 0.3053\n",
      "Epoch 390/500\n",
      "928/928 [==============================] - 0s 134us/step - loss: 0.3137 - mean_absolute_error: 0.3137 - val_loss: 0.3018 - val_mean_absolute_error: 0.3018\n",
      "Epoch 391/500\n",
      "928/928 [==============================] - 0s 138us/step - loss: 0.3125 - mean_absolute_error: 0.3125 - val_loss: 0.3029 - val_mean_absolute_error: 0.3029\n",
      "Epoch 392/500\n",
      "928/928 [==============================] - 0s 132us/step - loss: 0.3114 - mean_absolute_error: 0.3114 - val_loss: 0.3035 - val_mean_absolute_error: 0.3035\n",
      "Epoch 393/500\n",
      "928/928 [==============================] - 0s 159us/step - loss: 0.3123 - mean_absolute_error: 0.3123 - val_loss: 0.3026 - val_mean_absolute_error: 0.3026\n",
      "Epoch 394/500\n",
      "928/928 [==============================] - 0s 216us/step - loss: 0.3114 - mean_absolute_error: 0.3114 - val_loss: 0.3030 - val_mean_absolute_error: 0.3030\n",
      "Epoch 395/500\n",
      "928/928 [==============================] - 0s 154us/step - loss: 0.3114 - mean_absolute_error: 0.3114 - val_loss: 0.3027 - val_mean_absolute_error: 0.3027\n",
      "Epoch 396/500\n",
      "928/928 [==============================] - 0s 142us/step - loss: 0.3107 - mean_absolute_error: 0.3107 - val_loss: 0.3028 - val_mean_absolute_error: 0.3028\n",
      "Epoch 397/500\n",
      "928/928 [==============================] - 0s 163us/step - loss: 0.3132 - mean_absolute_error: 0.3132 - val_loss: 0.3030 - val_mean_absolute_error: 0.3030\n",
      "Epoch 398/500\n",
      "928/928 [==============================] - 0s 200us/step - loss: 0.3102 - mean_absolute_error: 0.3102 - val_loss: 0.3022 - val_mean_absolute_error: 0.3022\n",
      "Epoch 399/500\n",
      "928/928 [==============================] - 0s 157us/step - loss: 0.3128 - mean_absolute_error: 0.3128 - val_loss: 0.3019 - val_mean_absolute_error: 0.3019\n",
      "Epoch 400/500\n",
      "928/928 [==============================] - 0s 183us/step - loss: 0.3102 - mean_absolute_error: 0.3102 - val_loss: 0.3037 - val_mean_absolute_error: 0.3037\n",
      "Epoch 401/500\n",
      "928/928 [==============================] - 0s 152us/step - loss: 0.3120 - mean_absolute_error: 0.3120 - val_loss: 0.3066 - val_mean_absolute_error: 0.3066\n",
      "Epoch 402/500\n",
      "928/928 [==============================] - 0s 140us/step - loss: 0.3111 - mean_absolute_error: 0.3111 - val_loss: 0.3019 - val_mean_absolute_error: 0.3019\n",
      "Epoch 403/500\n",
      "928/928 [==============================] - 0s 160us/step - loss: 0.3108 - mean_absolute_error: 0.3108 - val_loss: 0.3027 - val_mean_absolute_error: 0.3027\n",
      "Epoch 404/500\n",
      "928/928 [==============================] - 0s 130us/step - loss: 0.3117 - mean_absolute_error: 0.3117 - val_loss: 0.3036 - val_mean_absolute_error: 0.3036\n",
      "Epoch 405/500\n",
      "928/928 [==============================] - 0s 158us/step - loss: 0.3113 - mean_absolute_error: 0.3113 - val_loss: 0.3022 - val_mean_absolute_error: 0.3022\n",
      "Epoch 406/500\n",
      "928/928 [==============================] - 0s 172us/step - loss: 0.3111 - mean_absolute_error: 0.3111 - val_loss: 0.3042 - val_mean_absolute_error: 0.3042\n",
      "Epoch 407/500\n",
      "928/928 [==============================] - 0s 193us/step - loss: 0.3116 - mean_absolute_error: 0.3116 - val_loss: 0.3018 - val_mean_absolute_error: 0.3018\n",
      "Epoch 408/500\n",
      "928/928 [==============================] - 0s 159us/step - loss: 0.3110 - mean_absolute_error: 0.3110 - val_loss: 0.3026 - val_mean_absolute_error: 0.3026\n",
      "Epoch 409/500\n",
      "928/928 [==============================] - 0s 141us/step - loss: 0.3099 - mean_absolute_error: 0.3099 - val_loss: 0.3020 - val_mean_absolute_error: 0.3020\n",
      "Epoch 410/500\n",
      "928/928 [==============================] - 0s 163us/step - loss: 0.3125 - mean_absolute_error: 0.3125 - val_loss: 0.3025 - val_mean_absolute_error: 0.3025\n",
      "Epoch 411/500\n",
      "928/928 [==============================] - 0s 162us/step - loss: 0.3115 - mean_absolute_error: 0.3115 - val_loss: 0.3026 - val_mean_absolute_error: 0.3026\n",
      "Epoch 412/500\n",
      "928/928 [==============================] - 0s 140us/step - loss: 0.3109 - mean_absolute_error: 0.3109 - val_loss: 0.3021 - val_mean_absolute_error: 0.3021\n",
      "Epoch 413/500\n",
      "928/928 [==============================] - 0s 157us/step - loss: 0.3112 - mean_absolute_error: 0.3112 - val_loss: 0.3030 - val_mean_absolute_error: 0.3030\n",
      "Epoch 414/500\n",
      "928/928 [==============================] - 0s 145us/step - loss: 0.3126 - mean_absolute_error: 0.3126 - val_loss: 0.3018 - val_mean_absolute_error: 0.3018\n",
      "Epoch 415/500\n",
      "928/928 [==============================] - 0s 148us/step - loss: 0.3110 - mean_absolute_error: 0.3110 - val_loss: 0.3043 - val_mean_absolute_error: 0.3043\n",
      "Epoch 416/500\n",
      "928/928 [==============================] - 0s 163us/step - loss: 0.3102 - mean_absolute_error: 0.3102 - val_loss: 0.3022 - val_mean_absolute_error: 0.3022\n",
      "Epoch 417/500\n",
      "928/928 [==============================] - 0s 155us/step - loss: 0.3124 - mean_absolute_error: 0.3124 - val_loss: 0.3022 - val_mean_absolute_error: 0.3022\n",
      "Epoch 418/500\n",
      "928/928 [==============================] - 0s 134us/step - loss: 0.3109 - mean_absolute_error: 0.3109 - val_loss: 0.3052 - val_mean_absolute_error: 0.3052\n",
      "Epoch 419/500\n",
      "928/928 [==============================] - 0s 146us/step - loss: 0.3122 - mean_absolute_error: 0.3122 - val_loss: 0.3027 - val_mean_absolute_error: 0.3027\n",
      "Epoch 420/500\n",
      "928/928 [==============================] - 0s 150us/step - loss: 0.3102 - mean_absolute_error: 0.3102 - val_loss: 0.3030 - val_mean_absolute_error: 0.3030\n",
      "Epoch 421/500\n",
      "928/928 [==============================] - 0s 154us/step - loss: 0.3115 - mean_absolute_error: 0.3115 - val_loss: 0.3096 - val_mean_absolute_error: 0.3096\n",
      "Epoch 422/500\n",
      "928/928 [==============================] - 0s 204us/step - loss: 0.3134 - mean_absolute_error: 0.3134 - val_loss: 0.3069 - val_mean_absolute_error: 0.3069\n",
      "Epoch 423/500\n",
      "928/928 [==============================] - 0s 164us/step - loss: 0.3134 - mean_absolute_error: 0.3134 - val_loss: 0.3019 - val_mean_absolute_error: 0.3019\n",
      "Epoch 424/500\n",
      "928/928 [==============================] - 0s 170us/step - loss: 0.3120 - mean_absolute_error: 0.3120 - val_loss: 0.3028 - val_mean_absolute_error: 0.3028\n",
      "Epoch 425/500\n",
      "928/928 [==============================] - 0s 147us/step - loss: 0.3112 - mean_absolute_error: 0.3112 - val_loss: 0.3103 - val_mean_absolute_error: 0.3103\n",
      "Epoch 426/500\n",
      "928/928 [==============================] - 0s 160us/step - loss: 0.3163 - mean_absolute_error: 0.3163 - val_loss: 0.3030 - val_mean_absolute_error: 0.3030\n",
      "Epoch 427/500\n",
      "928/928 [==============================] - 0s 178us/step - loss: 0.3140 - mean_absolute_error: 0.3140 - val_loss: 0.3091 - val_mean_absolute_error: 0.3091\n",
      "Epoch 428/500\n",
      "928/928 [==============================] - 0s 164us/step - loss: 0.3168 - mean_absolute_error: 0.3168 - val_loss: 0.3018 - val_mean_absolute_error: 0.3018\n",
      "Epoch 429/500\n",
      "928/928 [==============================] - 0s 152us/step - loss: 0.3119 - mean_absolute_error: 0.3119 - val_loss: 0.3018 - val_mean_absolute_error: 0.3018\n",
      "Epoch 430/500\n",
      "928/928 [==============================] - 0s 143us/step - loss: 0.3114 - mean_absolute_error: 0.3114 - val_loss: 0.3020 - val_mean_absolute_error: 0.3020\n",
      "Epoch 431/500\n",
      "928/928 [==============================] - 0s 181us/step - loss: 0.3128 - mean_absolute_error: 0.3128 - val_loss: 0.3031 - val_mean_absolute_error: 0.3031\n",
      "Epoch 432/500\n",
      "928/928 [==============================] - 0s 401us/step - loss: 0.3104 - mean_absolute_error: 0.3104 - val_loss: 0.3039 - val_mean_absolute_error: 0.3039\n",
      "Epoch 433/500\n",
      "928/928 [==============================] - 0s 166us/step - loss: 0.3103 - mean_absolute_error: 0.3103 - val_loss: 0.3045 - val_mean_absolute_error: 0.3045\n",
      "Epoch 434/500\n",
      "928/928 [==============================] - 0s 143us/step - loss: 0.3119 - mean_absolute_error: 0.3119 - val_loss: 0.3124 - val_mean_absolute_error: 0.3124\n",
      "Epoch 435/500\n",
      "928/928 [==============================] - 0s 192us/step - loss: 0.3106 - mean_absolute_error: 0.3106 - val_loss: 0.3023 - val_mean_absolute_error: 0.3023\n",
      "Epoch 436/500\n",
      "928/928 [==============================] - 0s 145us/step - loss: 0.3126 - mean_absolute_error: 0.3126 - val_loss: 0.3019 - val_mean_absolute_error: 0.3019\n",
      "Epoch 437/500\n",
      "928/928 [==============================] - 0s 140us/step - loss: 0.3126 - mean_absolute_error: 0.3126 - val_loss: 0.3019 - val_mean_absolute_error: 0.3019\n",
      "Epoch 438/500\n",
      "928/928 [==============================] - 0s 168us/step - loss: 0.3126 - mean_absolute_error: 0.3126 - val_loss: 0.3026 - val_mean_absolute_error: 0.3026\n",
      "Epoch 439/500\n",
      "928/928 [==============================] - 0s 146us/step - loss: 0.3102 - mean_absolute_error: 0.3102 - val_loss: 0.3081 - val_mean_absolute_error: 0.3081\n",
      "Epoch 440/500\n",
      "928/928 [==============================] - 0s 136us/step - loss: 0.3145 - mean_absolute_error: 0.3145 - val_loss: 0.3047 - val_mean_absolute_error: 0.3047\n",
      "Epoch 441/500\n",
      "928/928 [==============================] - 0s 146us/step - loss: 0.3128 - mean_absolute_error: 0.3128 - val_loss: 0.3042 - val_mean_absolute_error: 0.3042\n",
      "Epoch 442/500\n",
      "928/928 [==============================] - 0s 133us/step - loss: 0.3107 - mean_absolute_error: 0.3107 - val_loss: 0.3034 - val_mean_absolute_error: 0.3034\n",
      "Epoch 443/500\n",
      "928/928 [==============================] - 0s 169us/step - loss: 0.3113 - mean_absolute_error: 0.3113 - val_loss: 0.3034 - val_mean_absolute_error: 0.3034\n",
      "Epoch 444/500\n",
      "928/928 [==============================] - 0s 123us/step - loss: 0.3116 - mean_absolute_error: 0.3116 - val_loss: 0.3036 - val_mean_absolute_error: 0.3036\n",
      "Epoch 445/500\n",
      "928/928 [==============================] - 0s 198us/step - loss: 0.3121 - mean_absolute_error: 0.3121 - val_loss: 0.3024 - val_mean_absolute_error: 0.3024\n",
      "Epoch 446/500\n",
      "928/928 [==============================] - 0s 148us/step - loss: 0.3101 - mean_absolute_error: 0.3101 - val_loss: 0.3020 - val_mean_absolute_error: 0.3020\n",
      "Epoch 447/500\n",
      "928/928 [==============================] - 0s 126us/step - loss: 0.3112 - mean_absolute_error: 0.3112 - val_loss: 0.3021 - val_mean_absolute_error: 0.3021\n",
      "Epoch 448/500\n",
      "928/928 [==============================] - 0s 149us/step - loss: 0.3098 - mean_absolute_error: 0.3098 - val_loss: 0.3050 - val_mean_absolute_error: 0.3050\n",
      "Epoch 449/500\n",
      "928/928 [==============================] - 0s 125us/step - loss: 0.3129 - mean_absolute_error: 0.3129 - val_loss: 0.3019 - val_mean_absolute_error: 0.3019\n",
      "Epoch 450/500\n",
      "928/928 [==============================] - 0s 192us/step - loss: 0.3142 - mean_absolute_error: 0.3142 - val_loss: 0.3020 - val_mean_absolute_error: 0.3020\n",
      "Epoch 451/500\n",
      "928/928 [==============================] - 0s 149us/step - loss: 0.3097 - mean_absolute_error: 0.3097 - val_loss: 0.3029 - val_mean_absolute_error: 0.3029\n",
      "Epoch 452/500\n",
      "928/928 [==============================] - 0s 179us/step - loss: 0.3109 - mean_absolute_error: 0.3109 - val_loss: 0.3018 - val_mean_absolute_error: 0.3018\n",
      "Epoch 453/500\n",
      "928/928 [==============================] - 0s 161us/step - loss: 0.3124 - mean_absolute_error: 0.3124 - val_loss: 0.3020 - val_mean_absolute_error: 0.3020\n",
      "Epoch 454/500\n",
      "928/928 [==============================] - 0s 172us/step - loss: 0.3109 - mean_absolute_error: 0.3109 - val_loss: 0.3025 - val_mean_absolute_error: 0.3025\n",
      "Epoch 455/500\n",
      "928/928 [==============================] - 0s 169us/step - loss: 0.3117 - mean_absolute_error: 0.3117 - val_loss: 0.3038 - val_mean_absolute_error: 0.3038\n",
      "Epoch 456/500\n",
      "928/928 [==============================] - 0s 157us/step - loss: 0.3105 - mean_absolute_error: 0.3105 - val_loss: 0.3080 - val_mean_absolute_error: 0.3080\n",
      "Epoch 457/500\n",
      "928/928 [==============================] - 0s 245us/step - loss: 0.3112 - mean_absolute_error: 0.3112 - val_loss: 0.3041 - val_mean_absolute_error: 0.3041\n",
      "Epoch 458/500\n",
      "928/928 [==============================] - 0s 166us/step - loss: 0.3105 - mean_absolute_error: 0.3105 - val_loss: 0.3054 - val_mean_absolute_error: 0.3054\n",
      "Epoch 459/500\n",
      "928/928 [==============================] - 0s 155us/step - loss: 0.3118 - mean_absolute_error: 0.3118 - val_loss: 0.3075 - val_mean_absolute_error: 0.3075\n",
      "Epoch 460/500\n",
      "928/928 [==============================] - 0s 217us/step - loss: 0.3104 - mean_absolute_error: 0.3104 - val_loss: 0.3041 - val_mean_absolute_error: 0.3041\n",
      "Epoch 461/500\n",
      "928/928 [==============================] - 0s 154us/step - loss: 0.3141 - mean_absolute_error: 0.3141 - val_loss: 0.3019 - val_mean_absolute_error: 0.3019\n",
      "Epoch 462/500\n",
      "928/928 [==============================] - 0s 141us/step - loss: 0.3130 - mean_absolute_error: 0.3130 - val_loss: 0.3051 - val_mean_absolute_error: 0.3051\n",
      "Epoch 463/500\n",
      "928/928 [==============================] - 0s 139us/step - loss: 0.3148 - mean_absolute_error: 0.3148 - val_loss: 0.3023 - val_mean_absolute_error: 0.3023\n",
      "Epoch 464/500\n",
      "928/928 [==============================] - 0s 152us/step - loss: 0.3109 - mean_absolute_error: 0.3109 - val_loss: 0.3078 - val_mean_absolute_error: 0.3078\n",
      "Epoch 465/500\n",
      "928/928 [==============================] - 0s 135us/step - loss: 0.3134 - mean_absolute_error: 0.3134 - val_loss: 0.3020 - val_mean_absolute_error: 0.3020\n",
      "Epoch 466/500\n",
      "928/928 [==============================] - 0s 163us/step - loss: 0.3118 - mean_absolute_error: 0.3118 - val_loss: 0.3019 - val_mean_absolute_error: 0.3019\n",
      "Epoch 467/500\n",
      "928/928 [==============================] - 0s 155us/step - loss: 0.3107 - mean_absolute_error: 0.3107 - val_loss: 0.3021 - val_mean_absolute_error: 0.3021\n",
      "Epoch 468/500\n",
      "928/928 [==============================] - 0s 193us/step - loss: 0.3103 - mean_absolute_error: 0.3103 - val_loss: 0.3018 - val_mean_absolute_error: 0.3018\n",
      "Epoch 469/500\n",
      "928/928 [==============================] - 0s 248us/step - loss: 0.3143 - mean_absolute_error: 0.3143 - val_loss: 0.3020 - val_mean_absolute_error: 0.3020\n",
      "Epoch 470/500\n",
      "928/928 [==============================] - 0s 176us/step - loss: 0.3122 - mean_absolute_error: 0.3122 - val_loss: 0.3027 - val_mean_absolute_error: 0.3027\n",
      "Epoch 471/500\n",
      "928/928 [==============================] - 0s 153us/step - loss: 0.3161 - mean_absolute_error: 0.3161 - val_loss: 0.3022 - val_mean_absolute_error: 0.3022\n",
      "Epoch 472/500\n",
      "928/928 [==============================] - 0s 155us/step - loss: 0.3127 - mean_absolute_error: 0.3127 - val_loss: 0.3057 - val_mean_absolute_error: 0.3057\n",
      "Epoch 473/500\n",
      "928/928 [==============================] - 0s 156us/step - loss: 0.3107 - mean_absolute_error: 0.3107 - val_loss: 0.3023 - val_mean_absolute_error: 0.3023\n",
      "Epoch 474/500\n",
      "928/928 [==============================] - 0s 134us/step - loss: 0.3125 - mean_absolute_error: 0.3125 - val_loss: 0.3021 - val_mean_absolute_error: 0.3021\n",
      "Epoch 475/500\n",
      "928/928 [==============================] - 0s 163us/step - loss: 0.3118 - mean_absolute_error: 0.3118 - val_loss: 0.3024 - val_mean_absolute_error: 0.3024\n",
      "Epoch 476/500\n",
      "928/928 [==============================] - 0s 134us/step - loss: 0.3115 - mean_absolute_error: 0.3115 - val_loss: 0.3018 - val_mean_absolute_error: 0.3018\n",
      "Epoch 477/500\n",
      "928/928 [==============================] - 0s 161us/step - loss: 0.3108 - mean_absolute_error: 0.3108 - val_loss: 0.3062 - val_mean_absolute_error: 0.3062\n",
      "Epoch 478/500\n",
      "928/928 [==============================] - 0s 144us/step - loss: 0.3123 - mean_absolute_error: 0.3123 - val_loss: 0.3025 - val_mean_absolute_error: 0.3025\n",
      "Epoch 479/500\n",
      "928/928 [==============================] - 0s 130us/step - loss: 0.3130 - mean_absolute_error: 0.3130 - val_loss: 0.3019 - val_mean_absolute_error: 0.3019\n",
      "Epoch 480/500\n",
      "928/928 [==============================] - 0s 154us/step - loss: 0.3116 - mean_absolute_error: 0.3116 - val_loss: 0.3019 - val_mean_absolute_error: 0.3019\n",
      "Epoch 481/500\n",
      "928/928 [==============================] - 0s 135us/step - loss: 0.3115 - mean_absolute_error: 0.3115 - val_loss: 0.3061 - val_mean_absolute_error: 0.3061\n",
      "Epoch 482/500\n",
      "928/928 [==============================] - 0s 146us/step - loss: 0.3108 - mean_absolute_error: 0.3108 - val_loss: 0.3021 - val_mean_absolute_error: 0.3021\n",
      "Epoch 483/500\n",
      "928/928 [==============================] - 0s 220us/step - loss: 0.3117 - mean_absolute_error: 0.3117 - val_loss: 0.3024 - val_mean_absolute_error: 0.3024\n",
      "Epoch 484/500\n",
      "928/928 [==============================] - 0s 159us/step - loss: 0.3161 - mean_absolute_error: 0.3161 - val_loss: 0.3083 - val_mean_absolute_error: 0.3083\n",
      "Epoch 485/500\n",
      "928/928 [==============================] - 0s 161us/step - loss: 0.3197 - mean_absolute_error: 0.3197 - val_loss: 0.3039 - val_mean_absolute_error: 0.3039\n",
      "Epoch 486/500\n",
      "928/928 [==============================] - 0s 191us/step - loss: 0.3126 - mean_absolute_error: 0.3126 - val_loss: 0.3037 - val_mean_absolute_error: 0.3037\n",
      "Epoch 487/500\n",
      "928/928 [==============================] - 0s 150us/step - loss: 0.3100 - mean_absolute_error: 0.3100 - val_loss: 0.3021 - val_mean_absolute_error: 0.3021\n",
      "Epoch 488/500\n",
      "928/928 [==============================] - 0s 143us/step - loss: 0.3102 - mean_absolute_error: 0.3102 - val_loss: 0.3024 - val_mean_absolute_error: 0.3024\n",
      "Epoch 489/500\n",
      "928/928 [==============================] - 0s 131us/step - loss: 0.3137 - mean_absolute_error: 0.3137 - val_loss: 0.3020 - val_mean_absolute_error: 0.3020\n",
      "Epoch 490/500\n",
      "928/928 [==============================] - 0s 152us/step - loss: 0.3108 - mean_absolute_error: 0.3108 - val_loss: 0.3018 - val_mean_absolute_error: 0.3018\n",
      "Epoch 491/500\n",
      "928/928 [==============================] - 0s 264us/step - loss: 0.3122 - mean_absolute_error: 0.3122 - val_loss: 0.3052 - val_mean_absolute_error: 0.3052\n",
      "Epoch 492/500\n",
      "928/928 [==============================] - 0s 142us/step - loss: 0.3134 - mean_absolute_error: 0.3134 - val_loss: 0.3029 - val_mean_absolute_error: 0.3029\n",
      "Epoch 493/500\n",
      "928/928 [==============================] - 0s 154us/step - loss: 0.3139 - mean_absolute_error: 0.3139 - val_loss: 0.3020 - val_mean_absolute_error: 0.3020\n",
      "Epoch 494/500\n",
      "928/928 [==============================] - 0s 148us/step - loss: 0.3113 - mean_absolute_error: 0.3113 - val_loss: 0.3021 - val_mean_absolute_error: 0.3021\n",
      "Epoch 495/500\n",
      "928/928 [==============================] - 0s 133us/step - loss: 0.3111 - mean_absolute_error: 0.3111 - val_loss: 0.3037 - val_mean_absolute_error: 0.3037\n",
      "Epoch 496/500\n",
      "928/928 [==============================] - 0s 152us/step - loss: 0.3101 - mean_absolute_error: 0.3101 - val_loss: 0.3023 - val_mean_absolute_error: 0.3023\n",
      "Epoch 497/500\n",
      "928/928 [==============================] - 0s 143us/step - loss: 0.3138 - mean_absolute_error: 0.3138 - val_loss: 0.3198 - val_mean_absolute_error: 0.3198\n",
      "Epoch 498/500\n",
      "928/928 [==============================] - 0s 149us/step - loss: 0.3139 - mean_absolute_error: 0.3139 - val_loss: 0.3058 - val_mean_absolute_error: 0.3058\n",
      "Epoch 499/500\n",
      "928/928 [==============================] - 0s 176us/step - loss: 0.3106 - mean_absolute_error: 0.3106 - val_loss: 0.3019 - val_mean_absolute_error: 0.3019\n",
      "Epoch 500/500\n",
      "928/928 [==============================] - 0s 136us/step - loss: 0.3106 - mean_absolute_error: 0.3106 - val_loss: 0.3028 - val_mean_absolute_error: 0.3028\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e10d8d1048>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(input_train,labels_train,epochs=500,batch_size=32,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(input_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.031551083744152844\n"
     ]
    }
   ],
   "source": [
    "score = rmsle_validation(labels_test,yhat)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######################################### UNDER CONSTRUCTION ########################################################################## ###########################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model versus Deep Learning Network: Special pipeline\n",
    "dln_pipe = Pipeline([('OneHotEncoder',encoder),\n",
    "                     ('Normalizer',norm),\n",
    "                     ('StandardScaler',scaler),\n",
    "                     ('TruncatedSVD',TruncatedSVD(n_components=7))])\n",
    "\n",
    "input_train = torch.from_numpy(dln_pipe.fit_transform(X_train).astype('float64'))\n",
    "labels_train = torch.from_numpy(y_train.reshape(-1,1))\n",
    "input_test = torch.from_numpy(dln_pipe.fit_transform(X_test).astype('float64'))\n",
    "labels_test = torch.from_numpy(y_test.reshape(-1,1))\n",
    "\n",
    "if cuda.is_available:\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    \n",
    "print('Device is set to {}'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model versus Deep Learning Network: Create network\n",
    "model = nn.Sequential(nn.Linear(input_train.shape[1],500),\n",
    "                      nn.Dropout(p=0.2),\n",
    "                      nn.LeakyReLU(),\n",
    "                      nn.Linear(500,400),\n",
    "                      nn.Dropout(p=0.2),\n",
    "                      nn.LeakyReLU(),\n",
    "                      nn.Linear(400,300),\n",
    "                      nn.Dropout(p=0.2),\n",
    "                      nn.LeakyReLU(),\n",
    "                      nn.Linear(300,200),\n",
    "                      nn.Dropout(p=0.2),\n",
    "                      nn.LeakyReLU(),\n",
    "                      nn.Linear(200,100),\n",
    "                      nn.Dropout(p=0.2),\n",
    "                      nn.LeakyReLU(),\n",
    "                      nn.Linear(100,1),\n",
    "                      nn.LeakyReLU())\n",
    "\n",
    "# model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model versus Deep Learning Network: Defining validation function\n",
    "def model_validation(model,input_test,labels_test,criterion):\n",
    "    with torch.no_grad():\n",
    "#         input_test, labels_test = input_test.to(device), labels_test.to(device)\n",
    "        model.eval()\n",
    "        yhat = model(input_test.float())\n",
    "#         print(labels_test,yhat)\n",
    "        validation_score = rmsle(labels_test.numpy(),yhat.numpy())\n",
    "        validation_loss = criterion(yhat,labels_test.float())\n",
    "        \n",
    "    return validation_loss, validation_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model versus Deep Learning Network: Defining training parameters\n",
    "epochs = 10\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(),lr=0.1)\n",
    "\n",
    "trailing_train_loss = 0\n",
    "trailing_validation_loss = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "#     input_train, labels_train = input_train.to(device), labels_train.to(device)\n",
    "    yhat = model(input_train.float())\n",
    "    loss = criterion(yhat,labels_train.float())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    train_loss += loss.item()\n",
    "    \n",
    "    validation_loss, rmsle_score = model_validation(model,input_test,labels_test,criterion)\n",
    "    \n",
    "    trailing_train_loss += train_loss\n",
    "    trailing_validation_loss += validation_loss\n",
    "    \n",
    "    print('Epoch: {}/{}; Training loss: {}; Validation Loss: {}; RMSLE-Validation: {}'.format(epoch+1,epochs,train_loss,validation_loss,rmsle_score))\n",
    "    print('Training RMSLE: {}'.format(rmsle(labels_train.detach().numpy(),yhat.detach().numpy())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model versus Deep Learning Network: Visualizing results of Deep Learning model\n",
    "\n",
    "data = list(zip(trailing_train_loss,trailing_validation_loss))\n",
    "plt.plot(x=list(range(len(data))),y=data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
